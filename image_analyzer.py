#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ç”»åƒè§£æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
åŸºæœ¬çš„ãªç”»åƒè§£ææ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚
"""

import os
import sys
import base64
import json
import traceback
from io import BytesIO
import numpy as np
from PIL import Image
import cv2
import re
import math
from collections import Counter
import logging

try:
    import pytesseract
    from pytesseract import Output
    TESSERACT_AVAILABLE = True
except ImportError:
    TESSERACT_AVAILABLE = False

try:
    import easyocr
    EASYOCR_AVAILABLE = True
except ImportError:
    EASYOCR_AVAILABLE = False

try:
    from sklearn.cluster import KMeans
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

try:
    import tensorflow as tf
    import tensorflow.keras as keras
    TF_AVAILABLE = True
except ImportError:
    TF_AVAILABLE = False

try:
    from skimage.metrics import structural_similarity as ssim
    SKIMAGE_SSIM_AVAILABLE = True
except ImportError:
    SKIMAGE_SSIM_AVAILABLE = False

# å®šæ•°å®šç¾©
MAX_COLORS = 5
RESIZE_WIDTH = 300
MIN_SECTION_HEIGHT_RATIO = 0.05

# è‰²ã®å½¹å‰²ã‚’å®šç¾©
COLOR_ROLES = {
    'background': 'èƒŒæ™¯è‰²',
    'text': 'ãƒ†ã‚­ã‚¹ãƒˆè‰²',
    'accent': 'ã‚¢ã‚¯ã‚»ãƒ³ãƒˆè‰²',
    'primary': 'ãƒ—ãƒ©ã‚¤ãƒãƒªè‰²',
    'secondary': 'ã‚»ã‚«ãƒ³ãƒ€ãƒªè‰²'
}

# OCRèª¤èªè­˜è£œæ­£ç”¨ã®è¾æ›¸
OCR_CONFUSION_MAP = {
    '0': 'O',
    'O': '0',
    'l': 'I',
    'I': 'l',
    'rn': 'm',
    'm': 'rn',
    '1': 'l',
    'S': '5',
    '5': 'S',
    'G': '6',
    '6': 'G',
    'B': '8',
    '8': 'B',
    'Z': '2',
    '2': 'Z',
    'vv': 'w',
    'w': 'vv',
    'cl': 'd',
    'ri': 'n',
    'nn': 'm'
}

# UIã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—ã®å®šç¾©
SECTION_TYPES = {
    'hero': 'ãƒ’ãƒ¼ãƒ­ãƒ¼ã‚»ã‚¯ã‚·ãƒ§ãƒ³',
    'header': 'ãƒ˜ãƒƒãƒ€ãƒ¼ã‚»ã‚¯ã‚·ãƒ§ãƒ³',
    'footer': 'ãƒ•ãƒƒã‚¿ãƒ¼ã‚»ã‚¯ã‚·ãƒ§ãƒ³',
    'nav': 'ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³',
    'card-grid': 'ã‚«ãƒ¼ãƒ‰ã‚°ãƒªãƒƒãƒ‰',
    'features': 'ç‰¹å¾´èª¬æ˜',
    'about': 'æ¦‚è¦èª¬æ˜',
    'contact': 'ã‚³ãƒ³ã‚¿ã‚¯ãƒˆ',
    'testimonials': 'æ¨è–¦æ–‡',
    'pricing': 'ä¾¡æ ¼è¡¨',
    'gallery': 'ã‚®ãƒ£ãƒ©ãƒªãƒ¼',
    'cta': 'ã‚³ãƒ¼ãƒ«ãƒˆã‚¥ã‚¢ã‚¯ã‚·ãƒ§ãƒ³',
    'faq': 'ã‚ˆãã‚ã‚‹è³ªå•',
    'content': 'ä¸€èˆ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„'
}

# EasyOCRã®readerã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
_easyocr_reader = None

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logger = logging.getLogger('image_analyzer')

def get_easyocr_reader():
    """EasyOCRã®readerã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œï¼‰"""
    global _easyocr_reader
    if _easyocr_reader is None and EASYOCR_AVAILABLE:
        try:
            # GPUåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯GPUã‚’ä½¿ç”¨
            _easyocr_reader = easyocr.Reader(['ja', 'en'], gpu=True)
        except:
            try:
                # GPUåˆ©ç”¨å¤±æ•—æ™‚ã¯CPUãƒ¢ãƒ¼ãƒ‰ã§å†è©¦è¡Œ
                _easyocr_reader = easyocr.Reader(['ja', 'en'], gpu=False)
                logger.info("EasyOCR: CPUãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã—ã¾ã™")
            except Exception as e:
                logger.error(f"EasyOCRåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
                return None
    return _easyocr_reader


def decode_image(image_data):
    """base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¦OpenCVç”»åƒã«å¤‰æ›"""
    import base64
    import cv2
    import numpy as np

    try:
        # bytesã®å ´åˆã‚‚ str ã«å¤‰æ›ã—ãªã„ â†’ base64ã¨ã—ã¦æ‰±ã†å¿…è¦ã‚ã‚Š
        if isinstance(image_data, bytes):
            # Pythonã®BridgeçµŒç”±ã§ã¯bytesã§æ¥ã‚‹ã“ã¨ãŒã‚ã‚‹ã®ã§ã“ã“ã§base64å‡¦ç†ã—ã¦OK
            decoded = image_data
        elif isinstance(image_data, str):
            if 'base64,' in image_data:
                image_data = image_data.split('base64,')[1]
            decoded = base64.b64decode(image_data)
        else:
            raise ValueError("ç”»åƒãƒ‡ãƒ¼ã‚¿ã¯base64æ–‡å­—åˆ—ã¾ãŸã¯byteså½¢å¼ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")

        nparr = np.frombuffer(decoded, np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        return img
    except Exception as e:
        raise ValueError(f"ç”»åƒã®ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")


def extract_colors(image_data):
    """
    ç”»åƒã‹ã‚‰ä¸»è¦ãªè‰²ã‚’æŠ½å‡º

    Args:
        image_data: Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ‡ãƒ¼ã‚¿ã€ã¾ãŸã¯OpenCVã‚¤ãƒ¡ãƒ¼ã‚¸

    Returns:
        list: ä¸»è¦ãªè‰²ã®ãƒªã‚¹ãƒˆ
    """
    try:
        # ç”»åƒãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ã‚³ãƒ¼ãƒ‰å‡¦ç†
        if isinstance(image_data, str):
            img_data = decode_image(image_data)
            if not img_data:
                return []
            img = img_data['opencv']
        elif isinstance(image_data, dict) and 'opencv' in image_data:
            img = image_data['opencv']
        elif isinstance(image_data, np.ndarray):
            img = image_data
        else:
            return []

        height, width = img.shape[:2]

        # å‡¦ç†ã‚’é«˜é€ŸåŒ–ã™ã‚‹ãŸã‚ã«ãƒªã‚µã‚¤ã‚º
        scale = RESIZE_WIDTH / width
        small_img = cv2.resize(img, (0, 0), fx=scale, fy=scale)

        # K-meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã§è‰²æŠ½å‡º
        if SKLEARN_AVAILABLE:
            # ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
            pixels = small_img.reshape(-1, 3)
            pixels = pixels[:, ::-1]  # BGR to RGB

            # K-meansã§ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
            kmeans = KMeans(n_clusters=MAX_COLORS, n_init=10)
            kmeans.fit(pixels)

            # ã‚¯ãƒ©ã‚¹ã‚¿ã®ä¸­å¿ƒç‚¹ï¼ˆè‰²ï¼‰ã‚’å–å¾—
            colors = kmeans.cluster_centers_

            # ã‚¯ãƒ©ã‚¹ã‚¿ã®ã‚µã‚¤ã‚ºï¼ˆãƒ”ã‚¯ã‚»ãƒ«æ•°ï¼‰ã‚’å–å¾—
            labels = kmeans.labels_
            counts = Counter(labels)

            # çµæœã‚’æ•´å½¢
            color_info = []
            total_pixels = len(pixels)

            for i in range(MAX_COLORS):
                rgb = colors[i].astype(int)
                hex_color = '#{:02x}{:02x}{:02x}'.format(rgb[0], rgb[1], rgb[2])

                color_info.append({
                    'rgb': f'rgb({rgb[0]},{rgb[1]},{rgb[2]})',
                    'hex': hex_color,
                    'ratio': counts[i] / total_pixels
                })

            # ã‚µã‚¤ã‚ºé †ã«ã‚½ãƒ¼ãƒˆ
            color_info.sort(key=lambda x: x['ratio'], reverse=True)

            return color_info
        else:
            # scikit-learnãŒåˆ©ç”¨ã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            # ã‚ˆã‚Šå˜ç´”ãªæ–¹æ³•ã§è‰²ã‚’æŠ½å‡º
            # è‰²ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’è¨ˆç®—
            pixels = small_img.reshape(-1, 3)
            color_counts = {}

            for pixel in pixels:
                # è‰²ã®é‡å­åŒ–ï¼ˆé¡ä¼¼è‰²ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼‰
                quantized = (pixel[0] // 25 * 25, pixel[1] // 25 * 25, pixel[2] // 25 * 25)
                key = f"{quantized[2]},{quantized[1]},{quantized[0]}"  # RGBå½¢å¼
                color_counts[key] = color_counts.get(key, 0) + 1

            # é »åº¦é †ã«ã‚½ãƒ¼ãƒˆ
            sorted_colors = sorted(color_counts.items(), key=lambda x: x[1], reverse=True)
            top_colors = sorted_colors[:MAX_COLORS]

            # çµæœã‚’æ•´å½¢
            color_info = []
            total_pixels = len(pixels)

            for color_key, count in top_colors:
                r, g, b = map(int, color_key.split(','))
                hex_color = '#{:02x}{:02x}{:02x}'.format(r, g, b)

                color_info.append({
                    'rgb': f'rgb({r},{g},{b})',
                    'hex': hex_color,
                    'ratio': count / total_pixels
                })

            return color_info
    except Exception as e:
        logger.error(f"è‰²æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
        traceback.print_exc()
        return []

def extract_text(image_data):
    """
    ç”»åƒã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º

    Args:
        image_data: Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ‡ãƒ¼ã‚¿ã€ã¾ãŸã¯OpenCVã‚¤ãƒ¡ãƒ¼ã‚¸

    Returns:
        dict: æŠ½å‡ºã—ãŸãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
    """
    try:
        # ç”»åƒãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ã‚³ãƒ¼ãƒ‰å‡¦ç†
        if isinstance(image_data, str):
            img_data = decode_image(image_data)
            if not img_data:
                return {'text': '', 'textBlocks': []}
            img = img_data
        elif isinstance(image_data, dict) and 'opencv' in image_data:
            img = image_data['opencv']
        elif isinstance(image_data, np.ndarray):
            img = image_data
        else:
            return {'text': '', 'textBlocks': []}

        # ã¾ãšEasyOCRã§è©¦è¡Œï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
        result = None
        if EASYOCR_AVAILABLE:
            try:
                result = extract_text_with_easyocr(img)
                # ãƒ­ã‚°ã‚’printã‹ã‚‰loggingã«å¤‰æ›´
                logging.info("EasyOCRã§ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºå®Œäº†")
            except Exception as e:
                logging.error(f"EasyOCRã§ã®ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã«å¤±æ•—: {e}")
                result = None

        # EasyOCRå¤±æ•—ã¾ãŸã¯ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å ´åˆã¯Tesseractã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if result is None and TESSERACT_AVAILABLE:
            try:
                result = extract_text_with_tesseract(img)
                logging.info("Tesseractã§ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºå®Œäº†")
            except Exception as e:
                logging.error(f"Tesseractã§ã®ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã«å¤±æ•—: {e}")
                result = {'text': '', 'textBlocks': []}
        elif result is None:
            # ã©ã¡ã‚‰ã®OCRã‚‚åˆ©ç”¨ã§ããªã„å ´åˆ
            result = {'text': '', 'textBlocks': []}

        return result

    except Exception as e:
        logging.error(f"ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
        traceback.print_exc()
        return {'text': '', 'textBlocks': []}


def extract_text_with_easyocr(image, min_confidence=0.4):
    """
    EasyOCRã‚’ä½¿ç”¨ã—ã¦ç”»åƒã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹

    Args:
        image: å…¥åŠ›ç”»åƒï¼ˆNumPyé…åˆ—ï¼‰
        min_confidence: æ¤œå‡ºã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã®æœ€å°ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.4ï¼‰

    Returns:
        dict: æŠ½å‡ºã—ãŸãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
    """
    import easyocr
    import numpy as np
    import cv2
    import tempfile
    import os

    # ç”»åƒã®å‰å‡¦ç†ã‚’è¡Œã†
    # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã«å¤‰æ›
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·èª¿ï¼ˆCLAHEï¼‰
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(gray)

    # ãƒã‚¤ãƒ©ãƒ†ãƒ©ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ã§ãƒã‚¤ã‚ºä½æ¸›ï¼ˆã‚¨ãƒƒã‚¸ã¯ä¿æŒï¼‰
    filtered = cv2.bilateralFilter(enhanced, 9, 75, 75)

    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    temp_filename = 'temp_ocr_image.jpg'
    cv2.imwrite(temp_filename, filtered)

    try:
        # EasyOCRãƒªãƒ¼ãƒ€ãƒ¼ã®åˆæœŸåŒ–
        reader = easyocr.Reader(['ja', 'en'])

        # ãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡ºã®å®Ÿè¡Œï¼ˆdetail=1ã§ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã€ãƒ†ã‚­ã‚¹ãƒˆã€ä¿¡é ¼åº¦ã‚’å–å¾—ï¼‰
        results = reader.readtext(temp_filename, detail=1, paragraph=False)

        # çµæœã®æ•´å½¢ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        text_blocks = []
        full_text = []

        for item in results:
            # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«ã‚ˆã£ã¦æˆ»ã‚Šå€¤ã®å½¢å¼ãŒç•°ãªã‚‹ãŸã‚ã€å®‰å…¨ã«å‡¦ç†
            if len(item) == 3:
                bbox, text, confidence = item
            elif len(item) == 2:
                bbox, text = item
                confidence = 0.5  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼ˆä¸­ç¨‹åº¦ã®ä¿¡é ¼åº¦ï¼‰
            else:
                continue  # ä¸æ­£ãªãƒ‡ãƒ¼ã‚¿ã¯ã‚¹ã‚­ãƒƒãƒ—

            # ä¿¡é ¼åº¦ãŒé–¾å€¤ä»¥ä¸Šã®å ´åˆã®ã¿å‡¦ç†
            if confidence >= min_confidence:
                # ãƒ†ã‚­ã‚¹ãƒˆã®è£œæ­£å‡¦ç†
                corrected_text = correct_ocr_text(text)

                # è£œæ­£å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ãªã‘ã‚Œã°çµæœã«è¿½åŠ 
                if corrected_text:
                    # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®åº§æ¨™ã‚’å–å¾—
                    xs = [pt[0] for pt in bbox]
                    ys = [pt[1] for pt in bbox]
                    x = int(min(xs))
                    y = int(min(ys))
                    width = int(max(xs) - x)
                    height = int(max(ys) - y)

                    text_block = {
                        'text': corrected_text,
                        'confidence': float(confidence),
                        'position': {
                            'x': x,
                            'y': y,
                            'width': width,
                            'height': height
                        }
                    }

                    text_blocks.append(text_block)
                    full_text.append(corrected_text)

        # ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã‚’ä¿¡é ¼åº¦ã§ã‚½ãƒ¼ãƒˆ
        text_blocks.sort(key=lambda x: x['confidence'], reverse=True)

        return {
            'text': ' '.join(full_text),
            'textBlocks': text_blocks
        }
    except Exception as e:
        logger.error(f"EasyOCRã§ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        traceback.print_exc()
        raise
    finally:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
        try:
            if os.path.exists(temp_filename):
                os.remove(temp_filename)
        except:
            pass


def extract_text_with_tesseract(image):
    """
    Tesseractã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹ï¼ˆæ—¢å­˜ã®å®Ÿè£…ï¼‰

    Args:
        image: OpenCVç”»åƒ

    Returns:
        dict: æŠ½å‡ºã—ãŸãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
    """
    if not TESSERACT_AVAILABLE:
        return {'text': '', 'textBlocks': []}

    # Tesseractã®è¨­å®š
    custom_config = r'--oem 3 --psm 11'

    # OpenCVç”»åƒã‚’PILå½¢å¼ã«å¤‰æ›
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    pil_image = Image.fromarray(image_rgb)

    # Tesseractã§ãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡º
    data = pytesseract.image_to_data(pil_image, config=custom_config, output_type=Output.DICT)

    # çµæœã‚’æ•´å½¢
    text_blocks = []
    combined_text = []

    for i in range(len(data['text'])):
        # ç©ºã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—
        if data['text'][i].strip() == '':
            continue

        # ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’å–å¾—
        text = data['text'][i].strip()
        confidence = float(data['conf'][i]) / 100  # 0-1ã®ç¯„å›²ã«æ­£è¦åŒ–

        # ä¿¡é ¼åº¦ãŒä½ã„ã‚‚ã®ã¯ã‚¹ã‚­ãƒƒãƒ—
        if confidence < 0.3:
            continue

        # ãƒ†ã‚­ã‚¹ãƒˆã®è£œæ­£å‡¦ç†
        text = correct_ocr_text(text)

        # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®æƒ…å ±
        x = data['left'][i]
        y = data['top'][i]
        w = data['width'][i]
        h = data['height'][i]

        text_block = {
            'text': text,
            'confidence': confidence,
            'position': {
                'x': x,
                'y': y,
                'width': w,
                'height': h
            }
        }

        text_blocks.append(text_block)
        combined_text.append(text)

    # ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã‚’ä¿¡é ¼åº¦ã§ã‚½ãƒ¼ãƒˆ
    text_blocks.sort(key=lambda x: x['confidence'], reverse=True)

    return {
        'text': ' '.join(combined_text),
        'textBlocks': text_blocks
    }


def correct_ocr_text(text):
    """
    OCRã§æ¤œå‡ºã—ãŸãƒ†ã‚­ã‚¹ãƒˆã®ä¸€èˆ¬çš„ãªèª¤ã‚Šã‚’è£œæ­£ã™ã‚‹

    Args:
        text (str): è£œæ­£ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ

    Returns:
        str: è£œæ­£ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
    """
    if not text or not isinstance(text, str):
        return ""

    # ä½™åˆ†ãªç©ºç™½ã‚’1ã¤ã«ç½®æ›
    corrected = re.sub(r'\s+', ' ', text)

    # å…¨è§’/åŠè§’ã®çµ±ä¸€åŒ–ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
    # æ•°å­—ã¯åŠè§’ã«çµ±ä¸€
    corrected = re.sub(r'[ï¼-ï¼™]', lambda x: chr(ord(x.group(0)) - ord('ï¼') + ord('0')), corrected)

    # ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã¯åŠè§’ã«çµ±ä¸€
    corrected = re.sub(r'[ï½-ï½šï¼¡-ï¼º]', lambda x: chr(ord(x.group(0)) - ord('ï½') + ord('a') if 'ï½' <= x.group(0) <= 'ï½š' else ord(x.group(0)) - ord('ï¼¡') + ord('A')), corrected)

    # ä¸€èˆ¬çš„ãªOCRèª¤ã‚Šã®ä¿®æ­£
    replacements = {
        'l': '1',  # æ•°å­—ã®æ–‡è„ˆã§
        'O': '0',  # æ•°å­—ã®æ–‡è„ˆã§
        'ãƒ¼': '-',
        'ï¼Œ': ',',
        'ï¼': '.',
        'ã€': ',',
        'ã€‚': '.',
    }

    # ãƒ†ã‚­ã‚¹ãƒˆã®æ–‡è„ˆã«åŸºã¥ã„ã¦ç½®æ›ã‚’é©ç”¨
    # æ•°å­—ã®æ–‡è„ˆã‹ã©ã†ã‹ã‚’åˆ¤å®šï¼ˆå‘¨å›²ã«æ•°å­—ãŒã‚ã‚‹ã‹ï¼‰
    numeric_context = bool(re.search(r'\d[lO]\d|\d[lO]|[lO]\d', corrected))

    if numeric_context:
        for old, new in replacements.items():
            if old in ['l', 'O']:  # æ•°å­—ã®æ–‡è„ˆã§ã®ã¿ç½®æ›
                corrected = corrected.replace(old, new)

    # ãã®ä»–ã®ç½®æ›ã¯ã™ã¹ã¦ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§é©ç”¨
    for old, new in replacements.items():
        if old not in ['l', 'O']:
            corrected = corrected.replace(old, new)

    # å‰å¾Œã®ç©ºç™½ã‚’å‰Šé™¤
    corrected = corrected.strip()

    return corrected

def classify_section_type(section_data, all_sections=None, text_blocks=None):
    """
    ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚¿ã‚¤ãƒ—ã‚’åˆ†é¡ã™ã‚‹

    Args:
        section_data: ã‚»ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±
        all_sections: ã™ã¹ã¦ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±ï¼ˆä½ç½®é–¢ä¿‚ã®å‚ç…§ç”¨ï¼‰
        text_blocks: ç”»åƒå†…ã®ã™ã¹ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯

    Returns:
        string: ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—
    """
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ä½ç½®æƒ…å ±
    position = section_data.get('position', {})
    top = position.get('top', 0)
    height = position.get('height', 0)
    width = position.get('width', 0)

    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³å†…ã®ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
    section_texts = []
    text_types = {}  # ãƒ†ã‚­ã‚¹ãƒˆã®ç¨®é¡ã‚’ã‚«ã‚¦ãƒ³ãƒˆ

    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³å†…ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡º
    if text_blocks:
        for block in text_blocks:
            block_pos = block.get('position', {})
            block_y = block_pos.get('y', 0)
            block_height = block_pos.get('height', 0)

            # ã“ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ãŒã‚»ã‚¯ã‚·ãƒ§ãƒ³å†…ã«ã‚ã‚‹ã‹ç¢ºèª
            if (block_y >= top and block_y < top + height) or \
               (block_y + block_height > top and block_y + block_height <= top + height):
                text = block.get('text', '').lower()
                section_texts.append(text)

                # ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã®å½¹å‰²ã‚’å–å¾—
                role = block.get('role', '')
                if role:
                    if role not in text_types:
                        text_types[role] = 0
                    text_types[role] += 1

    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ä½ç½®ã«åŸºã¥ãåŸºæœ¬åˆ†é¡
    section_index = 0
    total_sections = 1
    if all_sections:
        # ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç‰¹å®š
        for i, section in enumerate(all_sections):
            if section == section_data:
                section_index = i
                break
        total_sections = len(all_sections)

    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç›¸å¯¾ä½ç½®
    is_first = section_index == 0
    is_last = section_index == total_sections - 1

    # 1. ä½ç½®ã«ã‚ˆã‚‹åŸºæœ¬åˆ†é¡
    if is_first and top < 200:
        basic_type = 'header'
    elif is_last and top > height * (total_sections - 1) * 0.7:
        basic_type = 'footer'
    else:
        basic_type = 'content'

    # 2. ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã«ã‚ˆã‚‹è©³ç´°åˆ†é¡
    # ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆã—ã¦æ¤œç´¢ã—ã‚„ã™ãã™ã‚‹
    combined_text = ' '.join(section_texts).lower()

    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®åˆ†é¡
    keyword_types = {
        'hero': ['welcome', 'hero', 'banner', 'main', 'top'],
        'about': ['about', 'story', 'mission', 'who we are', 'philosophy'],
        'features': ['features', 'services', 'what we do', 'benefits', 'advantages'],
        'testimonials': ['testimonial', 'review', 'feedback', 'client', 'what people say'],
        'pricing': ['pricing', 'plan', 'subscription', 'package', 'price', 'cost'],
        'contact': ['contact', 'reach', 'message', 'email', 'phone', 'call', 'touch'],
        'gallery': ['gallery', 'portfolio', 'work', 'project', 'image', 'photo'],
        'cta': ['sign up', 'register', 'join', 'subscribe', 'start', 'try', 'get started'],
        'faq': ['faq', 'question', 'answer', 'common', 'ask']
    }

    for type_name, keywords in keyword_types.items():
        for keyword in keywords:
            if keyword in combined_text:
                return type_name

    # 3. è¦‹å‡ºã—ã¨è¦ç´ ã®çµ„ã¿åˆã‚ã›ã«ã‚ˆã‚‹åˆ†é¡
    has_heading = 'heading' in text_types
    has_button = 'button' in text_types or 'cta' in combined_text
    has_form = 'text_input' in text_types or 'form' in combined_text
    has_long_text = 'paragraph' in text_types

    # ãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãåˆ†é¡
    if has_heading and has_button and is_first:
        return 'hero'
    elif has_form and ('contact' in combined_text or 'message' in combined_text):
        return 'contact'
    elif has_button and ('sign' in combined_text or 'join' in combined_text):
        return 'cta'
    elif is_first and basic_type == 'header':
        return 'header'
    elif is_last and basic_type == 'footer':
        return 'footer'
    elif has_long_text and 'about' in combined_text:
        return 'about'

    # 4. UIè¦ç´ ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚‹åˆ†é¡
    # è¦ç´ ã‚°ãƒ«ãƒ¼ãƒ—ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
    if section_data.get('elements'):
        elements = section_data.get('elements', [])

        # ã‚«ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
        card_count = sum(1 for e in elements if e.get('type') == 'card')
        if card_count >= 2:
            return 'card-grid'

        # ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
        has_nav = any(e.get('type') == 'nav' for e in elements)
        if has_nav:
            return 'nav'

    # 5. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåˆ†é¡
    # ã©ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚‚ä¸€è‡´ã—ãªã„å ´åˆã¯ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ä½ç½®ã«åŸºã¥ãåŸºæœ¬ã‚¿ã‚¤ãƒ—ã‚’è¿”ã™
    return basic_type


def analyze_sections(image_data):
    """
    ç”»åƒã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’åˆ†æ

    Args:
        image_data: Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ‡ãƒ¼ã‚¿ã€ã¾ãŸã¯OpenCVã‚¤ãƒ¡ãƒ¼ã‚¸

    Returns:
        dict: ã‚»ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±ã®ãƒªã‚¹ãƒˆ
    """
    try:
        # ç”»åƒãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ã‚³ãƒ¼ãƒ‰å‡¦ç†
        if isinstance(image_data, str):
            img_data = decode_image(image_data)
            if not img_data:
                return {'error': 'Failed to decode image', 'sections': []}
            img = img_data
        elif isinstance(image_data, dict) and 'opencv' in image_data:
            img = image_data['opencv']
        elif isinstance(image_data, np.ndarray):
            img = image_data
        else:
            return {'error': 'Invalid image data format', 'sections': []}

        height, width = img.shape[:2]

        # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã«å¤‰æ›
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # ãƒ–ãƒ©ãƒ¼å‡¦ç†
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)

        # æ°´å¹³æ–¹å‘ã®ã‚¨ãƒƒã‚¸ã‚’æ¤œå‡º
        sobelx = cv2.Sobel(blurred, cv2.CV_64F, 1, 0, ksize=3)
        sobelx = np.abs(sobelx)
        normalized_sobelx = cv2.normalize(sobelx, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)

        # æ°´å¹³å‹¾é…ã®å¹³å‡ã‚’è¨ˆç®—
        gradient_means = np.mean(normalized_sobelx, axis=1)

        # ãƒ”ãƒ¼ã‚¯ã‚’æ¤œå‡ºã—ã¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³å¢ƒç•Œã‚’ç‰¹å®š
        peak_indices = []
        min_peak_value = np.mean(gradient_means) * 1.5
        min_peak_distance = height * 0.05  # æœ€å°ãƒ”ãƒ¼ã‚¯é–“è·é›¢

        for i in range(1, len(gradient_means) - 1):
            if gradient_means[i] > min_peak_value and gradient_means[i] > gradient_means[i - 1] and gradient_means[i] > gradient_means[i + 1]:
                if not peak_indices or i - peak_indices[-1] > min_peak_distance:
                    peak_indices.append(i)

        # è¿½åŠ ã®å¢ƒç•Œã¨ã—ã¦ä¸Šç«¯ã¨ä¸‹ç«¯ã‚’è¨­å®š
        boundaries = [0] + peak_indices + [height - 1]

        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ
        sections = []

        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã”ã¨ã®æƒ…å ±ã‚’è§£æ
        for i in range(len(boundaries) - 1):
            top = boundaries[i]
            bottom = boundaries[i + 1]

            # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®é«˜ã•ãŒæœ€å°å€¤ä»¥ä¸‹ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if (bottom - top) < height * MIN_SECTION_HEIGHT_RATIO:
                continue

            # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”»åƒã‚’åˆ‡ã‚Šå‡ºã—
            section_img = img[top:bottom, 0:width]

            # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ä¸»è¦è‰²ã‚’å–å¾—
            dominant_color = get_dominant_color(section_img)

            # ã‚»ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’ä½œæˆ
            section = {
                'id': f'section_{i+1}',
                'position': {
                    'top': top,
                    'left': 0,
                    'width': width,
                    'height': bottom - top
                },
                'color': {
                    'dominant': dominant_color
                }
            }

            sections.append(section)

        # ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’æŠ½å‡ºã—ã¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«é–¢é€£ä»˜ã‘ï¼ˆåˆ†é¡ç”¨ï¼‰
        try:
            text_info = extract_text(image_data)
            text_blocks = text_info.get('textBlocks', [])
        except:
            text_blocks = []

        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç¨®é¡ã‚’åˆ†é¡
        for section in sections:
            section_type = classify_section_type(section, sections, text_blocks)
            section['section_type'] = section_type

        return {
            'sections': sections
        }
    except Exception as e:
        logger.error(f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
        traceback.print_exc()
        return {
            'error': str(e),
            'sections': []
        }

def get_dominant_color(img):
    """
    ç”»åƒã®ä¸»è¦ãªè‰²ã‚’æŠ½å‡º

    Args:
        img: OpenCVç”»åƒ

    Returns:
        dict: ä¸»è¦ãªè‰²æƒ…å ±
    """
    # å‡¦ç†ã‚’é«˜é€ŸåŒ–ã™ã‚‹ãŸã‚ã«ãƒªã‚µã‚¤ã‚º
    scale = min(1.0, 100.0 / max(img.shape[0], img.shape[1]))
    small_img = cv2.resize(img, (0, 0), fx=scale, fy=scale)

    # è‰²ã®å¹³å‡ã‚’è¨ˆç®—
    pixels = small_img.reshape(-1, 3)
    mean_color = np.mean(pixels, axis=0).astype(int)

    # BGR -> RGB
    r, g, b = mean_color[2], mean_color[1], mean_color[0]
    hex_color = '#{:02x}{:02x}{:02x}'.format(r, g, b)

    return {
        'rgb': f'rgb({r},{g},{b})',
        'hex': hex_color
    }

def analyze_layout(image_data):
    """
    ç”»åƒã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ

    Args:
        image_data: Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ‡ãƒ¼ã‚¿ã€ã¾ãŸã¯OpenCVã‚¤ãƒ¡ãƒ¼ã‚¸

    Returns:
        dict: ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆåˆ†æçµæœ
    """
    try:
        # ç”»åƒãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ã‚³ãƒ¼ãƒ‰å‡¦ç†
        if isinstance(image_data, str):
            img_data = decode_image(image_data)
            if not img_data:
                return {'error': 'Failed to decode image'}
            img = img_data['opencv']
        elif isinstance(image_data, dict) and 'opencv' in image_data:
            img = image_data['opencv']
        elif isinstance(image_data, np.ndarray):
            img = image_data
        else:
            return {'error': 'Invalid image data format'}

        height, width = img.shape[:2]

        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†æ
        sections = analyze_sections(image_data)

        # ç”»åƒã®åŸºæœ¬æƒ…å ±
        layout_info = {
            'layoutType': 'grid',  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            'confidence': 0.7,
            'layoutDetails': {
                'dimensions': {
                    'width': width,
                    'height': height,
                    'aspectRatio': width / height if height > 0 else 0
                },
                'sections': sections['sections'],
                'styles': {
                    'colors': extract_colors_from_image(image_data)
                }
            }
        }

        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¨æ¸¬
        aspect_ratio = width / height if height > 0 else 0
        num_sections = len(sections['sections'])

        if aspect_ratio > 2.0:
            layout_info['layoutType'] = 'horizontal_scroll'
            layout_info['confidence'] = 0.8
        elif aspect_ratio < 0.5:
            layout_info['layoutType'] = 'vertical_scroll'
            layout_info['confidence'] = 0.8
        elif num_sections == 0:
            layout_info['layoutType'] = 'single_view'
            layout_info['confidence'] = 0.9
        elif num_sections == 1:
            layout_info['layoutType'] = 'header_content'
            layout_info['confidence'] = 0.7
        elif num_sections == 2:
            layout_info['layoutType'] = 'header_content_footer'
            layout_info['confidence'] = 0.8
        elif num_sections >= 3:
            # ã‚¨ãƒƒã‚¸æ¤œå‡ºã¨ç·šæ¤œå‡ºã§ã‚°ãƒªãƒƒãƒ‰ã‚’æ¨æ¸¬
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            edges = cv2.Canny(gray, 50, 150)

            # ãƒãƒ•å¤‰æ›ã§ç·šã‚’æ¤œå‡º
            lines = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength=min(width, height)/4, maxLineGap=20)

            if lines is not None and len(lines) > 10:
                # æ°´å¹³ãƒ»å‚ç›´ç·šã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                h_lines = 0
                v_lines = 0

                for line in lines:
                    x1, y1, x2, y2 = line[0]

                    if abs(y2 - y1) < 10:  # æ°´å¹³ç·š
                        h_lines += 1
                    elif abs(x2 - x1) < 10:  # å‚ç›´ç·š
                        v_lines += 1

                # ã‚°ãƒªãƒƒãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ¤å®š
                if h_lines > 5 and v_lines > 5:
                    layout_info['layoutType'] = 'grid'
                    layout_info['confidence'] = 0.9
                elif h_lines > v_lines:
                    layout_info['layoutType'] = 'list'
                    layout_info['confidence'] = 0.8
                else:
                    layout_info['layoutType'] = 'columns'
                    layout_info['confidence'] = 0.7

        return layout_info
    except Exception as e:
        logger.error(f"ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
        traceback.print_exc()
        return {
            'error': str(e),
            'layoutType': 'unknown',
            'confidence': 0.5,
            'layoutDetails': {
                'dimensions': {'width': 0, 'height': 0, 'aspectRatio': 0},
                'sections': []
            }
        }

def detect_elements(image_data):
    """
    ç”»åƒã‹ã‚‰UIã®ä¸»è¦ãªè¦ç´ ã‚’æ¤œå‡º

    Args:
        image_data: Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ‡ãƒ¼ã‚¿ã€ã¾ãŸã¯OpenCVã‚¤ãƒ¡ãƒ¼ã‚¸

    Returns:
        dict: æ¤œå‡ºã•ã‚ŒãŸè¦ç´ 
    """
    try:
        # ç”»åƒãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ã‚³ãƒ¼ãƒ‰å‡¦ç†
        if isinstance(image_data, str):
            img_data = decode_image(image_data)
            if not img_data:
                return {'error': 'Failed to decode image', 'elements': []}
            img = img_data['opencv']
        elif isinstance(image_data, dict) and 'opencv' in image_data:
            img = image_data['opencv']
        elif isinstance(image_data, np.ndarray):
            img = image_data
        else:
            return {'error': 'Invalid image data format', 'elements': []}

        height, width = img.shape[:2]

        # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã«å¤‰æ›
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # ã‚¨ãƒƒã‚¸æ¤œå‡º
        edges = cv2.Canny(gray, 50, 150)

        # è¼ªéƒ­æ¤œå‡º
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # è¦ç´ æ¤œå‡ºçµæœ
        elements = []
        min_area = (width * height) * 0.005  # æœ€å°é¢ç©

        for contour in contours:
            area = cv2.contourArea(contour)

            # å°ã•ã™ãã‚‹è¼ªéƒ­ã¯ç„¡è¦–
            if area < min_area:
                continue

            # è¼ªéƒ­ã®å¤–æ¥çŸ©å½¢ã‚’å–å¾—
            x, y, w, h = cv2.boundingRect(contour)

            # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’è¨ˆç®—
            aspect_ratio = w / h if h > 0 else 0

            # è¦ç´ ã®ä¸­å¿ƒéƒ¨åˆ†ã®ç”»åƒã‚’æŠ½å‡º
            element_img = img[y:y+h, x:x+w]

            # è¦ç´ ã®ç¨®é¡ã‚’æ¨æ¸¬
            element_type = classify_element(element_img, aspect_ratio)

            # è¦ç´ æƒ…å ±ã‚’è¿½åŠ 
            elements.append({
                'type': element_type,
                'position': {
                    'x': x,
                    'y': y,
                    'width': w,
                    'height': h,
                    'center': [x + w // 2, y + h // 2]
                },
                'color': get_dominant_color(element_img)
            })

        return {'elements': elements}
    except Exception as e:
        logger.error(f"è¦ç´ æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
        traceback.print_exc()
        return {'error': str(e), 'elements': []}

def classify_element(element_img, aspect_ratio):
    """
    UIè¦ç´ ã®ç¨®é¡ã‚’åˆ†é¡

    Args:
        element_img: è¦ç´ ã®ç”»åƒ
        aspect_ratio: ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”

    Returns:
        str: è¦ç´ ã®ç¨®é¡
    """
    # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã§å¤§ã¾ã‹ã«åˆ†é¡
    if aspect_ratio > 5.0:
        return 'header'
    elif aspect_ratio > 3.0:
        return 'text_input'
    elif aspect_ratio < 0.3:
        return 'sidebar'
    elif 0.9 < aspect_ratio < 1.1:
        # ã»ã¼æ­£æ–¹å½¢ã®å ´åˆ
        # ãƒ†ã‚­ã‚¹ãƒˆã‚’å«ã‚€ã‹ãƒã‚§ãƒƒã‚¯
        if TESSERACT_AVAILABLE:
            text = pytesseract.image_to_string(element_img)
            if len(text.strip()) > 0:
                return 'button'
        return 'card'
    else:
        # ãã®ä»–ã®å ´åˆ
        if element_img.shape[0] < 100:
            return 'button'
        return 'content_section'

def main():
    """
    ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‹ã‚‰æ©Ÿèƒ½ã‚’å®Ÿè¡Œ
    """
    if len(sys.argv) < 3:
        print('ä½¿ç”¨æ³•: python image_analyzer.py [æ©Ÿèƒ½] [ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹]')
        return

    command = sys.argv[1]
    file_path = sys.argv[2]

    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        with open(file_path, 'rb') as f:
            image_data = f.read()

        # OpenCVã§ç”»åƒã‚’èª­ã¿è¾¼ã¿
        nparr = np.frombuffer(image_data, np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img is None:
            raise ValueError(f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ: {file_path}")

        result = None

        # ã‚³ãƒãƒ³ãƒ‰ã«å¿œã˜ã¦æ©Ÿèƒ½ã‚’å®Ÿè¡Œ
        if command == 'extract_colors':
            result = extract_colors(img)
        elif command == 'extract_text':
            result = extract_text(img)
        elif command == 'analyze_sections':
            result = analyze_sections(img)
        elif command == 'analyze_layout':
            result = analyze_layout(img)
        elif command == 'detect_elements':
            result = detect_elements(img)
        elif command == 'analyze_all':
            # ã™ã¹ã¦ã®åˆ†æã‚’å®Ÿè¡Œ
            layout = analyze_layout(img)
            elements = detect_elements(img)
            text = extract_text(img)

            result = {
                'layout': layout,
                'elements': elements['elements'],
                'text': text
            }
        else:
            result = {'error': f'Unknown command: {command}'}

        # çµæœã‚’JSONå½¢å¼ã§å‡ºåŠ›
        print(json.dumps(result))
    except Exception as e:
        print(json.dumps({
            'error': str(e),
            'traceback': traceback.format_exc()
        }))

if __name__ == '__main__':
    main()

# Python Bridge ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ç”¨ã®é–¢æ•°
def extract_colors_from_image(image, **options):
    """
    Python Bridgeã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ç”¨ã®è‰²æŠ½å‡ºé–¢æ•°

    Args:
        image: decode_imageã®çµæœã€ã¾ãŸã¯ç”»åƒãƒ‡ãƒ¼ã‚¿
        options: è¿½åŠ ã‚ªãƒ—ã‚·ãƒ§ãƒ³

    Returns:
        list: è‰²æƒ…å ±ã®ãƒªã‚¹ãƒˆ
    """
    try:
        # ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒç›´æ¥æ¸¡ã•ã‚ŒãŸå ´åˆã¯å‡¦ç†
        if isinstance(image, str):
            image = decode_image(image)

        # ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒé©åˆ‡ãªå½¢å¼ã‹ãƒã‚§ãƒƒã‚¯
        if isinstance(image, dict) and 'opencv' in image:
            colors = extract_colors(image['opencv'])
        elif isinstance(image, np.ndarray):
            colors = extract_colors(image)
        else:
            colors = extract_colors(image)

        # è©³ç´°ãªãƒ­ã‚°å‡ºåŠ›ã‚’è¿½åŠ 
        logger.info("========== è‰²æŠ½å‡ºçµæœã®è©³ç´°ãƒ­ã‚°é–‹å§‹ ==========")

        # æŠ½å‡ºã•ã‚ŒãŸè‰²ã®æ•°
        logger.info(f"æŠ½å‡ºã•ã‚ŒãŸè‰²ã®æ•°: {len(colors)}")

        # å„è‰²ã®è©³ç´°ã‚’ãƒ­ã‚°ã«å‡ºåŠ›
        for i, color in enumerate(colors):
            logger.info(f"è‰² {i+1}:")
            logger.info(f"  RGB: {color.get('rgb', '')}")
            logger.info(f"  HEX: {color.get('hex', '')}")
            logger.info(f"  æ¯”ç‡: {color.get('ratio', 0):.4f} ({color.get('ratio', 0)*100:.2f}%)")
            if 'role' in color:
                logger.info(f"  å½¹å‰²: {color.get('role', 'ä¸æ˜')}")

        logger.info("========== è‰²æŠ½å‡ºçµæœã®è©³ç´°ãƒ­ã‚°çµ‚äº† ==========")

        return colors
    except Exception as e:
        logger.error(f"è‰²æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
        traceback.print_exc()
        return []

def extract_text_from_image(image, **options):
    """
    Python Bridgeã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºé–¢æ•°

    Args:
        image: decode_imageã®çµæœã€ã¾ãŸã¯ç”»åƒãƒ‡ãƒ¼ã‚¿
        options: è¿½åŠ ã‚ªãƒ—ã‚·ãƒ§ãƒ³

    Returns:
        dict: ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
    """
    try:
        # ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒç›´æ¥æ¸¡ã•ã‚ŒãŸå ´åˆã¯å‡¦ç†
        if isinstance(image, str):
            image = decode_image(image)

        # ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒé©åˆ‡ãªå½¢å¼ã‹ãƒã‚§ãƒƒã‚¯
        if isinstance(image, dict) and 'opencv' in image:
            result = extract_text(image['opencv'])
        elif isinstance(image, np.ndarray):
            result = extract_text(image)
        else:
            result = extract_text(image)

        # è©³ç´°ãªãƒ­ã‚°å‡ºåŠ›ã‚’è¿½åŠ 
        logger.info("========== ç”»åƒè§£æçµæœã®è©³ç´°ãƒ­ã‚°é–‹å§‹ ==========")

        # ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºçµæœã®è©³ç´°ã‚’ãƒ­ã‚°ã«å‡ºåŠ›
        logger.info(f"æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆå…¨ä½“: {result.get('text', '')}")

        # ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã®è©³ç´°ã‚’ãƒ­ã‚°ã«å‡ºåŠ›
        text_blocks = result.get('textBlocks', [])
        logger.info(f"ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯æ•°: {len(text_blocks)}")

        for i, block in enumerate(text_blocks):
            logger.info(f"ãƒ–ãƒ­ãƒƒã‚¯ {i+1}:")
            logger.info(f"  ãƒ†ã‚­ã‚¹ãƒˆ: {block.get('text', '')}")
            logger.info(f"  ä¿¡é ¼åº¦: {block.get('confidence', 0):.3f}")
            if 'position' in block:
                pos = block['position']
                logger.info(f"  ä½ç½®: x={pos.get('x', 0)}, y={pos.get('y', 0)}, å¹…={pos.get('width', 0)}, é«˜ã•={pos.get('height', 0)}")

        logger.info("========== ç”»åƒè§£æçµæœã®è©³ç´°ãƒ­ã‚°çµ‚äº† ==========")

        return result
    except Exception as e:
        logger.error(f"ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
        traceback.print_exc()
        return {
            'text': '',
            'error': str(e),
            'textBlocks': []
        }

def analyze_image_sections(image, **options):
    """
    Python Bridgeã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ç”¨ã®ç”»åƒã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†æé–¢æ•°

    Args:
        image: decode_imageã®çµæœã€ã¾ãŸã¯ç”»åƒãƒ‡ãƒ¼ã‚¿
        options: è¿½åŠ ã‚ªãƒ—ã‚·ãƒ§ãƒ³

    Returns:
        dict: ã‚»ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±
    """
    try:
        # ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒç›´æ¥æ¸¡ã•ã‚ŒãŸå ´åˆã¯å‡¦ç†
        if isinstance(image, str):
            image = decode_image(image)

        # ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒé©åˆ‡ãªå½¢å¼ã‹ãƒã‚§ãƒƒã‚¯
        if isinstance(image, dict) and 'opencv' in image:
            return analyze_sections(image['opencv'])
        elif isinstance(image, np.ndarray):
            return analyze_sections(image)
        else:
            return analyze_sections(image)
    except Exception as e:
        logger.error(f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
        traceback.print_exc()
        return {
            'sections': [],
            'error': str(e)
        }

def analyze_layout_pattern(image, **options):
    """
    Python Bridgeã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ç”¨ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æé–¢æ•°

    Args:
        image: decode_imageã®çµæœã€ã¾ãŸã¯ç”»åƒãƒ‡ãƒ¼ã‚¿
        options: è¿½åŠ ã‚ªãƒ—ã‚·ãƒ§ãƒ³

    Returns:
        dict: ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³æƒ…å ±
    """
    try:
        # ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒç›´æ¥æ¸¡ã•ã‚ŒãŸå ´åˆã¯å‡¦ç†
        if isinstance(image, str):
            image = decode_image(image)

        # ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒé©åˆ‡ãªå½¢å¼ã‹ãƒã‚§ãƒƒã‚¯
        if isinstance(image, dict) and 'opencv' in image:
            layout = analyze_layout(image['opencv'])
        elif isinstance(image, np.ndarray):
            layout = analyze_layout(image)
        else:
            layout = analyze_layout(image)

        # è©³ç´°ãªãƒ­ã‚°å‡ºåŠ›ã‚’è¿½åŠ 
        logger.info("========== ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆåˆ†æçµæœã®è©³ç´°ãƒ­ã‚°é–‹å§‹ ==========")

        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚¿ã‚¤ãƒ—ã¨ä¿¡é ¼åº¦
        logger.info(f"ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚¿ã‚¤ãƒ—: {layout.get('layoutType', 'unknown')}")
        logger.info(f"ä¿¡é ¼åº¦: {layout.get('confidence', 0):.3f}")

        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè©³ç´°ãŒã‚ã‚Œã°å‡ºåŠ›
        if 'layoutDetails' in layout:
            layout_details = layout.get('layoutDetails', {})
            dimensions = layout_details.get('dimensions', {})
            logger.info(f"ç”»åƒã‚µã‚¤ã‚º: å¹…={dimensions.get('width', 0)}px, é«˜ã•={dimensions.get('height', 0)}px")

            sections = layout_details.get('sections', [])
            logger.info(f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ•°: {len(sections)}")

            # å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®è©³ç´°
            for i, section in enumerate(sections):
                logger.info(f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³ {i+1}:")
                section_type = section.get('type', 'ä¸æ˜')
                section_pos = section.get('position', {})
                logger.info(f"  ã‚¿ã‚¤ãƒ—: {section_type}")
                logger.info(f"  ä½ç½®: top={section_pos.get('top', 0)}, left={section_pos.get('left', 0)}, ")
                logger.info(f"       å¹…={section_pos.get('width', 0)}, é«˜ã•={section_pos.get('height', 0)}")

                # ã‚»ã‚¯ã‚·ãƒ§ãƒ³å†…ã®è¦ç´ ãŒã‚ã‚Œã°å‡ºåŠ›
                elements = section.get('elements', [])
                if elements:
                    logger.info(f"  è¦ç´ æ•°: {len(elements)}")

        logger.info("========== ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆåˆ†æçµæœã®è©³ç´°ãƒ­ã‚°çµ‚äº† ==========")

        return layout
    except Exception as e:
        logger.error(f"ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
        traceback.print_exc()
        return {
            'layout': 'unknown',
            'confidence': 0.0,
            'error': str(e)
        }

def detect_feature_elements(image, **options):
    """
    Python Bridgeã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ç”¨ã®ç‰¹å¾´è¦ç´ æ¤œå‡ºé–¢æ•°

    Args:
        image: decode_imageã®çµæœã€ã¾ãŸã¯ç”»åƒãƒ‡ãƒ¼ã‚¿
        options: è¿½åŠ ã‚ªãƒ—ã‚·ãƒ§ãƒ³

    Returns:
        list: æ¤œå‡ºã•ã‚ŒãŸè¦ç´ ã®ãƒªã‚¹ãƒˆ
    """
    try:
        # ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒç›´æ¥æ¸¡ã•ã‚ŒãŸå ´åˆã¯å‡¦ç†
        if isinstance(image, str):
            image = decode_image(image)

        # ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒé©åˆ‡ãªå½¢å¼ã‹ãƒã‚§ãƒƒã‚¯
        if isinstance(image, dict) and 'opencv' in image:
            elements = detect_elements(image['opencv'])
        elif isinstance(image, np.ndarray):
            elements = detect_elements(image)
        else:
            elements = detect_elements(image)

        # è©³ç´°ãªãƒ­ã‚°å‡ºåŠ›ã‚’è¿½åŠ 
        logger.info("========== è¦ç´ æ¤œå‡ºçµæœã®è©³ç´°ãƒ­ã‚°é–‹å§‹ ==========")

        # æ¤œå‡ºã•ã‚ŒãŸè¦ç´ ã®æ•°
        if isinstance(elements, list):
            element_count = len(elements)
        elif isinstance(elements, dict) and 'elements' in elements:
            elements = elements.get('elements', [])
            element_count = len(elements)
        else:
            element_count = 0
            elements = []

        logger.info(f"æ¤œå‡ºã•ã‚ŒãŸè¦ç´ ã®æ•°: {element_count}")

        # å„è¦ç´ ã®è©³ç´°ã‚’ãƒ­ã‚°ã«å‡ºåŠ›
        element_types = {}
        for i, element in enumerate(elements):
            logger.info(f"è¦ç´  {i+1}:")
            element_type = element.get('type', 'ä¸æ˜')
            logger.info(f"  ç¨®é¡: {element_type}")
            logger.info(f"  ä¿¡é ¼åº¦: {element.get('confidence', 0):.3f}")

            # ä½ç½®æƒ…å ±ãŒã‚ã‚Œã°å‡ºåŠ›
            if 'position' in element:
                pos = element['position']
                logger.info(f"  ä½ç½®: x={pos.get('x', 0)}, y={pos.get('y', 0)}, å¹…={pos.get('width', 0)}, é«˜ã•={pos.get('height', 0)}")

            # ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ãŒã‚ã‚Œã°å‡ºåŠ›
            if 'text' in element:
                logger.info(f"  ãƒ†ã‚­ã‚¹ãƒˆ: {element.get('text', '')}")

            # è¦ç´ ã‚¿ã‚¤ãƒ—ã®é›†è¨ˆ
            if element_type not in element_types:
                element_types[element_type] = 0
            element_types[element_type] += 1

        # è¦ç´ ã‚¿ã‚¤ãƒ—ã®ã‚µãƒãƒªãƒ¼ã‚’å‡ºåŠ›
        logger.info("è¦ç´ ã‚¿ã‚¤ãƒ—ã®ã‚µãƒãƒªãƒ¼:")
        for elem_type, count in element_types.items():
            logger.info(f"  {elem_type}: {count}å€‹")

        logger.info("========== è¦ç´ æ¤œå‡ºçµæœã®è©³ç´°ãƒ­ã‚°çµ‚äº† ==========")

        return elements
    except Exception as e:
        logger.error(f"ç‰¹å¾´è¦ç´ æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
        traceback.print_exc()
        return []

# æ–°ã—ã„é–¢æ•°ã‚’è¿½åŠ 
def compress_analysis_results(analysis_data, options=None):
    """
    ç”»åƒè§£æçµæœã‚’3å±¤æ§‹é€ ã«åœ§ç¸®ã—ã€å¿…è¦ãªæƒ…å ±ã®ã¿ã‚’ä¿æŒã—ã¾ã™ã€‚

    Args:
        analysis_data: å…ƒã®è§£æçµæœè¾æ›¸
        options: åœ§ç¸®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆçœç•¥å¯èƒ½ï¼‰

    Returns:
        dict: åœ§ç¸®ã•ã‚ŒãŸè§£æçµæœ
    """
    logger.info("ğŸ§  åœ§ç¸®å‡¦ç†ã‚’é–‹å§‹ï¼ˆcompress_analysis_resultsï¼‰")

    options = options or {}

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®è¨­å®š
    min_text_confidence = options.get('min_text_confidence', 0.6)
    max_colors = options.get('max_colors', 5)
    include_sections = options.get('include_sections', True)
    include_layout = options.get('include_layout', True)
    include_colors = options.get('include_colors', True)
    include_text = options.get('include_text', True)
    include_elements = options.get('include_elements', True)

    # åˆæœŸåŒ–
    compressed = {}
    text_hierarchy = []
    filtered_blocks = []

    # ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã®å‡¦ç†ï¼ˆç¬¬1å±¤åœ§ç¸®ï¼‰
    if 'text' in analysis_data and include_text:
        text_data = analysis_data['text']

        logger.info(f"â–¶ï¸ å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯æ•°: {len(text_data.get('textBlocks', []))}")
        original_text_length = len(text_data.get('text', ''))
        logger.info(f"â–¶ï¸ å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆé•·: {original_text_length}æ–‡å­—")

        if 'textBlocks' in text_data:
            # ä¿¡é ¼åº¦ã®é«˜ã„ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã®ã¿ä¿æŒ
            blocks = text_data['textBlocks']

            # ä¿¡é ¼åº¦ã§ã‚½ãƒ¼ãƒˆ
            blocks.sort(key=lambda x: x.get('confidence', 0), reverse=True)

            excluded_blocks = 0
            for block in blocks:
                confidence = block.get('confidence', 0)
                if confidence >= min_text_confidence:
                    # ãƒ†ã‚­ã‚¹ãƒˆéšå±¤ã¨å½¹å‰²ã‚’æ¨å®š
                    role = estimate_text_role(block, blocks)
                    block['role'] = role
                    filtered_blocks.append(block)

                    # éšå±¤æ§‹é€ ã«ãƒãƒƒãƒ”ãƒ³ã‚°
                    level = 3  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ãƒ¬ãƒ™ãƒ«3ï¼ˆæœ¬æ–‡ï¼‰
                    if role == 'heading':
                        level = 1
                    elif role == 'subheading':
                        level = 2

                    # é«˜ä¿¡é ¼åº¦ã®ãƒ–ãƒ­ãƒƒã‚¯ã¯ä¿¡é ¼åº¦æƒ…å ±ã‚’çœç•¥å¯èƒ½
                    text_item = {
                        'level': level,
                        'text': block.get('text', '')
                    }

                    # ä¿¡é ¼åº¦ãŒä½ã„å ´åˆã®ã¿ä¿¡é ¼åº¦ã‚’å«ã‚ã‚‹
                    if confidence < 0.9:
                        text_item['confidence'] = round(confidence, 2)

                    text_hierarchy.append(text_item)
                else:
                    excluded_blocks += 1

            logger.info(f"âœ… åœ§ç¸®å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯æ•°: {len(filtered_blocks)} (é™¤å¤–: {excluded_blocks})")

        compressed['text'] = {
            'content': text_data.get('text', ''),
            'hierarchy': text_hierarchy
        }

    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæƒ…å ±ã®å‡¦ç†ï¼ˆç¬¬2å±¤åœ§ç¸®ï¼‰
    if 'layout' in analysis_data and include_layout:
        layout_data = analysis_data['layout']
        layout_type = layout_data.get('layoutType', 'unknown')

        logger.info(f"ğŸ–¼ï¸ æ¤œå‡ºã•ã‚ŒãŸãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚¿ã‚¤ãƒ—: {layout_type}")

        layout_details = layout_data.get('layoutDetails', {})
        dimensions = layout_details.get('dimensions', {})
        width = dimensions.get('width', 0)
        height = dimensions.get('height', 0)

        # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’è¨ˆç®—
        aspect_ratio = "unknown"
        if width and height:
            ratio = width / height
            if abs(ratio - 16/9) < 0.2:
                aspect_ratio = "16:9"
            elif abs(ratio - 4/3) < 0.2:
                aspect_ratio = "4:3"
            elif abs(ratio - 1) < 0.2:
                aspect_ratio = "1:1"
            else:
                aspect_ratio = f"{round(ratio, 1)}:1"

        # ã‚°ãƒªãƒƒãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
        grid_pattern = detect_grid_pattern(layout_details)

        logger.info(f"ğŸ“ ç”»åƒã‚µã‚¤ã‚º: {width}x{height}px (ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”: {aspect_ratio})")
        logger.info(f"ğŸ“ ã‚°ãƒªãƒƒãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³: {grid_pattern.get('type', 'unknown')}")

        compressed['layout'] = {
            'type': layout_type,
            'aspectRatio': aspect_ratio,
            'width': width,
            'height': height,
            'gridPattern': grid_pattern.get('type', 'unknown')
        }

    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±ã®å‡¦ç†
    if 'sections' in analysis_data and include_sections:
        sections_data = analysis_data['sections']
        section_list = sections_data.get('sections', [])

        logger.info(f"ğŸ§© å…ƒã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ•°: {len(section_list)}")

        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç¨®é¡ã‚’åˆ†é¡
        classified_sections = []
        section_types = {}

        for section in section_list:
            section_type = classify_section_type(section, section_list, filtered_blocks)
            section['section_type'] = section_type
            classified_sections.append(section)

            # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            if section_type not in section_types:
                section_types[section_type] = 0
            section_types[section_type] += 1

        logger.info(f"ğŸ§© ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—å†…è¨³: {section_types}")
        compressed['sections'] = classified_sections

    # è‰²æƒ…å ±ã®å‡¦ç†ï¼ˆç¬¬3å±¤åœ§ç¸®ï¼‰
    if 'colors' in analysis_data and include_colors:
        colors = []
        if isinstance(analysis_data['colors'], list):
            colors = analysis_data['colors']

        logger.info(f"ğŸ¨ å…ƒã®è‰²æ•°: {len(colors)}")

        # é¡ä¼¼è‰²ã®çµ±åˆ
        merged_colors = merge_similar_colors(colors, max_colors)

        # è‰²ã®å½¹å‰²ã‚’æ¨å®š
        colors_with_roles = estimate_color_roles(merged_colors, analysis_data)

        # è‰²æƒ…å ±ã‚’ç°¡ç•¥åŒ–
        final_colors = []
        for color in colors_with_roles[:max_colors]:
            role = color.get('role', '')
            final_colors.append({
                'hex': color.get('hex', ''),
                'role': role,
                'ratio': round(color.get('ratio', 0), 2) if color.get('ratio', 0) > 0.05 else None
            })

        compressed['colors'] = final_colors
        logger.info(f"ğŸ¨ åœ§ç¸®å¾Œã®è‰²æ•°: {len(final_colors)}")

    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®ä¿æŒ
    if 'timestamp' in analysis_data:
        compressed['timestamp'] = analysis_data['timestamp']

    # æœ€çµ‚çš„ãªåœ§ç¸®çµæœã®ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
    import json
    compressed_json = json.dumps(compressed)
    compressed_size = len(compressed_json)
    logger.info(f"ğŸ“¦ åœ§ç¸®å¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {compressed_size}ãƒã‚¤ãƒˆ")
    logger.info("âœ… åœ§ç¸®å‡¦ç†å®Œäº†ï¼ˆcompress_analysis_resultsï¼‰")

    return compressed

def convert_to_semantic_format(compressed_data):
    """
    åœ§ç¸®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚¿ã‚°å½¢å¼ã«å¤‰æ›

    Args:
        compressed_data: åœ§ç¸®æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿

    Returns:
        str: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚¿ã‚°å½¢å¼ã®æ–‡å­—åˆ—
    """
    result = []

    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæƒ…å ±
    layout = compressed_data.get('layout', {})
    result.append(f"[layout:{layout.get('template', 'unknown')}]")

    if layout.get('imagePosition'):
        result.append(f"[image-position:{layout.get('imagePosition')}]")

    if layout.get('textPosition'):
        result.append(f"[text-position:{layout.get('textPosition')}]")

    # ãƒ†ã‚­ã‚¹ãƒˆéšå±¤
    text_data = compressed_data.get('text', {})
    for item in text_data.get('hierarchy', []):
        level = item.get('level', 3)
        text = item.get('text', '')

        if level == 1:
            result.append(f"[heading] {text}")
        elif level == 2:
            result.append(f"[subheading] {text}")
        else:
            result.append(f"[text] {text}")

    # è‰²æƒ…å ±
    colors = compressed_data.get('colors', [])
    color_parts = []
    for color in colors:
        role = color.get('role', '')
        hex_code = color.get('hex', '')
        if role and hex_code:
            color_parts.append(f"{role}={hex_code}")

    if color_parts:
        result.append(f"[colors:{','.join(color_parts)}]")

    return "\n".join(result)


def convert_to_template_format(compressed_data):
    """
    åœ§ç¸®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå½¢å¼ã«å¤‰æ›

    Args:
        compressed_data: åœ§ç¸®æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿

    Returns:
        str: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå½¢å¼ã®æ–‡å­—åˆ—
    """
    result = []

    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
    layout = compressed_data.get('layout', {})
    result.append(f"{{{{layout:{layout.get('template', 'unknown')}}}}}")

    # è¦‹å‡ºã—
    headings = []
    subheadings = []
    body_texts = []

    text_data = compressed_data.get('text', {})
    for item in text_data.get('hierarchy', []):
        level = item.get('level', 3)
        text = item.get('text', '')

        if level == 1:
            headings.append(text)
        elif level == 2:
            subheadings.append(text)
        else:
            body_texts.append(text)

    if headings:
        result.append(f"{{{{heading:{headings[0]}}}}}")

    if subheadings:
        result.append(f"{{{{subheading:{' / '.join(subheadings)}}}}}")

    if body_texts:
        result.append(f"{{{{body:{' / '.join(body_texts)}}}}}")

    # è‰²æƒ…å ±
    colors = compressed_data.get('colors', [])
    color_parts = []
    for color in colors:
        role = color.get('role', '')
        hex_code = color.get('hex', '')
        if role and hex_code:
            short_role = role[0:2] if role in ['background', 'primary', 'secondary'] else role
            color_parts.append(f"{short_role}={hex_code}")

    if color_parts:
        result.append(f"{{{{colors:{','.join(color_parts)}}}}}")

    return "\n".join(result)

def merge_similar_colors(colors, max_colors=5):
    """é¡ä¼¼ã™ã‚‹è‰²ã‚’ãƒãƒ¼ã‚¸ã—ã¦ä»£è¡¨çš„ãªè‰²ã«é›†ç´„ã™ã‚‹"""
    if not colors:
        return []

    # æ—¢ã«æœ€å¤§è‰²æ•°ä»¥ä¸‹ãªã‚‰ãã®ã¾ã¾è¿”ã™
    if len(colors) <= max_colors:
        return colors

    # è‰²ç›¸ã¨å½©åº¦ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼ˆLABè‰²ç©ºé–“ãŒç†æƒ³ã ãŒã€ç°¡ç•¥åŒ–ã®ãŸã‚RGBãƒ™ãƒ¼ã‚¹ï¼‰
    from sklearn.cluster import KMeans
    import numpy as np

    # RGBå€¤ã‚’æŠ½å‡º
    rgb_values = []
    for color in colors:
        rgb_str = color.get('rgb', '')
        # 'rgb(r,g,b)' å½¢å¼ã‹ã‚‰æ•°å€¤ã‚’æŠ½å‡º
        if 'rgb(' in rgb_str and ')' in rgb_str:
            rgb_parts = rgb_str.replace('rgb(', '').replace(')', '').split(',')
            if len(rgb_parts) == 3:
                try:
                    r, g, b = map(int, rgb_parts)
                    rgb_values.append([r, g, b])
                except ValueError:
                    continue

    if not rgb_values:
        return colors[:max_colors]

    # KMeansã§è‰²ã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
    rgb_array = np.array(rgb_values)
    kmeans = KMeans(n_clusters=max_colors, n_init=10)
    kmeans.fit(rgb_array)

    # å„ã‚¯ãƒ©ã‚¹ã‚¿ã®ä»£è¡¨è‰²ã¨ãã‚Œã«å±ã™ã‚‹å…ƒã®è‰²ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
    cluster_centers = kmeans.cluster_centers_.astype(int)
    labels = kmeans.labels_

    # æ–°ã—ã„è‰²æƒ…å ±ã‚’ä½œæˆ
    merged_colors = []
    for i in range(max_colors):
        # ã“ã®ã‚¯ãƒ©ã‚¹ã‚¿ã«å±ã™ã‚‹è‰²ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
        indices = [j for j, label in enumerate(labels) if label == i]
        if not indices:
            continue

        # ã“ã®ã‚¯ãƒ©ã‚¹ã‚¿ã®ä»£è¡¨çš„ãªRGBå€¤
        r, g, b = cluster_centers[i]
        hex_color = '#{:02x}{:02x}{:02x}'.format(r, g, b)

        # ã“ã®ã‚¯ãƒ©ã‚¹ã‚¿ã«å±ã™ã‚‹è‰²ã®åˆè¨ˆæ¯”ç‡ã‚’è¨ˆç®—
        total_ratio = sum(colors[j]['ratio'] for j in indices if j < len(colors))

        merged_colors.append({
            'rgb': f'rgb({r},{g},{b})',
            'hex': hex_color,
            'ratio': total_ratio
        })

    # æ¯”ç‡ã§ã‚½ãƒ¼ãƒˆ
    merged_colors.sort(key=lambda x: x['ratio'], reverse=True)

    return merged_colors


def estimate_color_roles(colors, analysis_data=None):
    """
    è‰²ã«å¯¾ã—ã¦æƒ³å®šã•ã‚Œã‚‹å½¹å‰²ï¼ˆèƒŒæ™¯ã€å‰æ™¯ã€ã‚¢ã‚¯ã‚»ãƒ³ãƒˆç­‰ï¼‰ã‚’æ¨å®šã—ã¾ã™ã€‚

    Args:
        colors: è‰²æƒ…å ±ã®ãƒªã‚¹ãƒˆ
        analysis_data: å…¨ä½“ã®è§£æãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

    Returns:
        list: å½¹å‰²ãŒè¿½åŠ ã•ã‚ŒãŸè‰²ã®ãƒªã‚¹ãƒˆ
    """
    logger.info("ğŸ­ è‰²ã®å½¹å‰²æ¨å®šå‡¦ç†ã‚’é–‹å§‹ï¼ˆestimate_color_rolesï¼‰")

    # è‰²ãŒç©ºã®å ´åˆã¯ç©ºã®ãƒªã‚¹ãƒˆã‚’è¿”ã™
    if not colors or len(colors) == 0:
        logger.info("âš ï¸ è‰²æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“")
        return []

    # è‰²æƒ…å ±ã‚’æ¯”ç‡ã§ã‚½ãƒ¼ãƒˆ
    sorted_colors = sorted(colors, key=lambda x: x.get('ratio', 0), reverse=True)

    # å½¹å‰²ãŒè¿½åŠ ã•ã‚ŒãŸè‰²ãƒªã‚¹ãƒˆ
    colors_with_roles = []

    # ä½¿ç”¨æ¸ˆã¿ã®å½¹å‰²ã‚’è¿½è·¡
    used_roles = set()

    # å„è‰²ã«å½¹å‰²ã‚’å‰²ã‚Šå½“ã¦
    for idx, color in enumerate(sorted_colors):
        hex_color = color.get('hex', '')
        ratio = color.get('ratio', 0)

        # RGBå€¤ã®å–å¾—ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
        rgb_values = None
        if 'rgb' in color:
            rgb_str = color['rgb']
            # rgb(r,g,b)å½¢å¼ã‹ã‚‰æ•°å€¤ã‚’æŠ½å‡º
            import re
            rgb_match = re.match(r'rgb\((\d+),(\d+),(\d+)\)', rgb_str)
            if rgb_match:
                r, g, b = map(int, rgb_match.groups())
                rgb_values = (r, g, b)

        # æ˜åº¦ã®è¨ˆç®—ï¼ˆRGBå€¤ãŒã‚ã‚‹å ´åˆï¼‰
        brightness = 0
        if rgb_values:
            r, g, b = rgb_values
            brightness = (0.299 * r + 0.587 * g + 0.114 * b) / 255

        # å½¹å‰²ã®åˆæœŸåŒ–
        role = "unknown"

        # æœ€ã‚‚å¤šã„è‰²ã¯é€šå¸¸èƒŒæ™¯è‰²
        if idx == 0 and ratio > 0.3:
            role = "background"
        # 2ç•ªç›®ã«å¤šã„è‰²ã§æ˜åº¦ãŒä½ã„å ´åˆã¯ãƒ†ã‚­ã‚¹ãƒˆè‰²
        elif idx == 1 and brightness < 0.5 and ratio > 0.05:
            role = "text"
        # 2ç•ªç›®ã«å¤šã„è‰²ã§æ˜åº¦ãŒé«˜ã„å ´åˆã¯å‰æ™¯è‰²
        elif idx == 1 and brightness >= 0.5 and ratio > 0.05:
            role = "foreground"
        # ä½¿ç”¨ç‡ãŒä½ãã€å½©åº¦ãŒé«˜ã„è‰²ã¯ã‚¢ã‚¯ã‚»ãƒ³ãƒˆè‰²
        elif ratio < 0.1 and idx > 1 and is_saturated(rgb_values) and "accent" not in used_roles:
            role = "accent"
        # 3ç•ªç›®ä»¥é™ã®ä½¿ç”¨ç‡ãŒä¸­ç¨‹åº¦ã®è‰²ã¯è£œåŠ©è‰²
        elif idx >= 2 and ratio > 0.05 and ratio < 0.3:
            role = "secondary"
        # ä½¿ç”¨ç‡ãŒéå¸¸ã«ä½ã„è‰²ã¯è£…é£¾è‰²
        elif ratio < 0.05:
            role = "decorative"

        # æ–‡è„ˆã«åŸºã¥ãå½¹å‰²ã®èª¿æ•´
        # ä¾‹ï¼šç”»åƒãŒå†™çœŸã®å ´åˆã¯ç•°ãªã‚‹è§£é‡ˆã‚’ã™ã‚‹
        if analysis_data and 'imageType' in analysis_data:
            image_type = analysis_data.get('imageType', '')
            if image_type == 'photo':
                # å†™çœŸã®å ´åˆã®å½¹å‰²èª¿æ•´
                if idx == 0:
                    role = "dominant"
                elif idx == 1:
                    role = "secondary"
                elif is_saturated(rgb_values) and ratio > 0.05:
                    role = "accent"
            elif image_type == 'screenshot':
                # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®å ´åˆã®å½¹å‰²èª¿æ•´
                if idx == 0 and brightness > 0.8:
                    role = "background"
                elif idx == 1 and brightness < 0.2:
                    role = "text"

        # ä½¿ç”¨æ¸ˆã¿å½¹å‰²ã«è¿½åŠ 
        used_roles.add(role)

        # å½¹å‰²ã‚’è‰²æƒ…å ±ã«è¿½åŠ 
        color_with_role = color.copy()
        color_with_role['role'] = role
        colors_with_roles.append(color_with_role)

        logger.info(f"ğŸ¨ è‰² {idx+1}: HEX={hex_color}, æ¯”ç‡={ratio:.2f}({ratio*100:.1f}%), å½¹å‰²={role}")

    logger.info(f"âœ… è‰²ã®å½¹å‰²æ¨å®šå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼ˆå…¨{len(colors_with_roles)}è‰²ï¼‰")
    return colors_with_roles

def estimate_text_role(text_block, all_blocks):
    """ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã®å½¹å‰²ï¼ˆè¦‹å‡ºã—ã€æœ¬æ–‡ãªã©ï¼‰ã‚’æ¨å®šã™ã‚‹"""
    if not text_block:
        return 'unknown'

    text = text_block.get('text', '')
    position = text_block.get('position', {})
    confidence = text_block.get('confidence', 0)

    # ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã‹ä¿¡é ¼åº¦ãŒä½ã„å ´åˆ
    if not text or confidence < 0.3:
        return 'unknown'

    # ä½ç½®æƒ…å ±
    y_position = position.get('y', 0)
    height = position.get('height', 0)
    width = position.get('width', 0)

    # ãƒ†ã‚­ã‚¹ãƒˆã®é•·ã•
    text_length = len(text)

    # å¤§æ–‡å­—æ¯”ç‡
    uppercase_ratio = sum(1 for c in text if c.isupper()) / max(1, len(text))

    # è¦‹å‡ºã—ã®ç‰¹å¾´: çŸ­ã„ãƒ†ã‚­ã‚¹ãƒˆã€ä¸Šéƒ¨ã«ã‚ã‚‹ã€å¤§ããªãƒ•ã‚©ãƒ³ãƒˆ
    if (text_length < 30 and y_position < 200 and height > 20) or uppercase_ratio > 0.7:
        return 'heading'

    # ã‚µãƒ–è¦‹å‡ºã—ã®ç‰¹å¾´: ä¸­ç¨‹åº¦ã®é•·ã•ã€ä¸­ç¨‹åº¦ã®ãƒ•ã‚©ãƒ³ãƒˆ
    elif text_length < 100 and 10 < height < 20:
        return 'subheading'

    # ãƒœã‚¿ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ç‰¹å¾´: éå¸¸ã«çŸ­ã„ãƒ†ã‚­ã‚¹ãƒˆã€ç‰¹å®šã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    elif text_length < 20 and any(keyword in text.lower() for keyword in ['submit', 'login', 'sign', 'buy', 'view', 'more', 'click', 'go']):
        return 'button'

    # ãƒªãƒ³ã‚¯ãƒ†ã‚­ã‚¹ãƒˆã®ç‰¹å¾´
    elif any(keyword in text.lower() for keyword in ['http', 'www', '.com', '.jp']):
        return 'link'

    # æœ¬æ–‡ãƒ†ã‚­ã‚¹ãƒˆã®ç‰¹å¾´: é•·ã„ãƒ†ã‚­ã‚¹ãƒˆ
    elif text_length > 100:
        return 'paragraph'

    # ãã®ä»–ã®ãƒ©ãƒ™ãƒ«ãƒ†ã‚­ã‚¹ãƒˆ
    elif text_length < 50:
        return 'label'

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    return 'text'


def detect_grid_pattern(layout_details):
    """ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‹ã‚‰ã‚°ãƒªãƒƒãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡ºã™ã‚‹"""
    # ç”»åƒã®ã‚µã‚¤ã‚ºæƒ…å ±ã‚’å–å¾—
    dimensions = layout_details.get('dimensions', {})
    width = dimensions.get('width', 0)
    height = dimensions.get('height', 0)

    if not width or not height:
        return {'type': 'unknown'}

    # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã«åŸºã¥ã„ã¦åŸºæœ¬ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚¿ã‚¤ãƒ—ã‚’æ¨å®š
    aspect_ratio = width / height if height > 0 else 0

    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—
    sections = layout_details.get('sections', [])
    num_sections = len(sections)

    # åŸºæœ¬çš„ãªã‚°ãƒªãƒƒãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¨å®š
    if aspect_ratio > 2.0:
        grid_type = 'horizontal'
        column_count = min(num_sections, 4)
        row_count = 1
    elif aspect_ratio < 0.5:
        grid_type = 'vertical'
        column_count = 1
        row_count = min(num_sections, 4)
    elif num_sections <= 1:
        grid_type = 'single'
        column_count = 1
        row_count = 1
    elif num_sections <= 3:
        # ãƒ˜ãƒƒãƒ€ãƒ¼ãƒ»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ»ãƒ•ãƒƒã‚¿ãƒ¼æ§‹é€ ã®å¯èƒ½æ€§
        grid_type = 'header_content_footer'
        column_count = 1
        row_count = num_sections
    else:
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ä½ç½®é–¢ä¿‚ã‹ã‚‰åˆ—æ•°ã‚’æ¨å®š
        columns = estimate_column_count(sections, width)
        grid_type = 'grid'
        column_count = columns
        row_count = max(1, num_sections // columns)

    return {
        'type': grid_type,
        'columns': column_count,
        'rows': row_count,
        'aspect_ratio': aspect_ratio
    }


def estimate_column_count(sections, total_width):
    """ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®é…ç½®ã‹ã‚‰åˆ—æ•°ã‚’æ¨å®šã™ã‚‹"""
    if not sections or total_width == 0:
        return 1

    # å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®æ°´å¹³æ–¹å‘ã®ä¸­å¿ƒä½ç½®ã‚’å–å¾—
    centers = []
    for section in sections:
        position = section.get('position', {})
        left = position.get('left', 0)
        width = position.get('width', 0)
        if width > 0:
            center_x = left + width / 2
            centers.append(center_x)

    if not centers:
        return 1

    # ä¸­å¿ƒä½ç½®ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã§åˆ—ã‚’æ¨å®š
    from sklearn.cluster import KMeans
    import numpy as np

    # 1åˆ—ã‹ã‚‰4åˆ—ã¾ã§ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚’è©¦ã—ã¦æœ€é©ãªåˆ—æ•°ã‚’è¦‹ã¤ã‘ã‚‹
    best_columns = 1
    best_score = float('inf')

    for columns in range(1, min(5, len(centers) + 1)):
        X = np.array(centers).reshape(-1, 1)
        kmeans = KMeans(n_clusters=columns, n_init=10)
        kmeans.fit(X)

        # ã‚¯ãƒ©ã‚¹ã‚¿å†…ã®åˆ†æ•£ã‚’è©•ä¾¡ã‚¹ã‚³ã‚¢ã¨ã—ã¦ä½¿ç”¨
        score = kmeans.inertia_
        normalized_score = score / columns  # åˆ—æ•°ã§æ­£è¦åŒ–

        if normalized_score < best_score * 0.7:  # 70%ä»¥ä¸Šã®æ”¹å–„ãŒã‚ã‚Œã°æ¡ç”¨
            best_score = normalized_score
            best_columns = columns

    return best_columns


def summarize_sections(sections):
    """ã‚»ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±ã®ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆã™ã‚‹"""
    if not sections:
        return []

    summaries = []
    for i, section in enumerate(sections):
        position = section.get('position', {})
        color = section.get('color', {}).get('dominant', {})

        # ãƒã‚¸ã‚·ãƒ§ãƒ³ã‹ã‚‰ç›¸å¯¾çš„ãªä½ç½®ã‚’æ¨å®š
        relative_position = 'unknown'
        top = position.get('top', 0)
        height = position.get('height', 0)

        if 'top' in position:
            if i == 0:
                relative_position = 'top'
            elif i == len(sections) - 1:
                relative_position = 'bottom'
            else:
                relative_position = 'middle'

        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—ã‚’å–å¾—ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰ã¾ãŸã¯æ¨å®š
        section_type = section.get('section_type', '')
        if not section_type:
            # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—ãŒãªã„å ´åˆã€ä½ç½®ãƒ™ãƒ¼ã‚¹ã§æ¨å®š
            if i == 0 and top < 150:
                section_type = 'header'
            elif i == len(sections) - 1 and height < 200:
                section_type = 'footer'
            elif height < 100:
                section_type = 'divider'
            else:
                section_type = 'content'

        summaries.append({
            'index': i,
            'type': section_type,
            'position': relative_position,
            'height': height,
            'color': color.get('hex', '') if color else ''
        })

    return summaries

def compare_images(original_image, rendered_image, mask=None):
    """
    åŸç”»åƒã¨ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ç”»åƒã‚’æ¯”è¼ƒã—ã¦é¡ä¼¼åº¦ã‚’è©•ä¾¡ã™ã‚‹

    Args:
        original_image: ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒï¼ˆOpenCVã‚¤ãƒ¡ãƒ¼ã‚¸ï¼‰
        rendered_image: ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã•ã‚ŒãŸç”»åƒï¼ˆOpenCVã‚¤ãƒ¡ãƒ¼ã‚¸ï¼‰
        mask: æ¯”è¼ƒæ™‚ã«ä½¿ç”¨ã™ã‚‹ãƒã‚¹ã‚¯ç”»åƒï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

    Returns:
        dict: é¡ä¼¼åº¦è©•ä¾¡çµæœ
    """
    try:
        # ä¸¡æ–¹ã®ç”»åƒãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
        if original_image is None or rendered_image is None:
            return {
                'success': False,
                'error': 'One or both images are missing',
                'ssim_score': 0,
                'differences': None
            }

        # ç”»åƒã‚µã‚¤ã‚ºã‚’ä¸€è‡´ã•ã›ã‚‹
        height_orig, width_orig = original_image.shape[:2]
        height_rendered, width_rendered = rendered_image.shape[:2]

        # ã‚µã‚¤ã‚ºãŒç•°ãªã‚‹å ´åˆã¯ã€ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ç”»åƒã‚’ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ã‚µã‚¤ã‚ºã«ãƒªã‚µã‚¤ã‚º
        if height_orig != height_rendered or width_orig != width_rendered:
            rendered_image = cv2.resize(rendered_image, (width_orig, height_orig),
                                        interpolation=cv2.INTER_AREA)

        # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã«å¤‰æ›
        original_gray = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)
        rendered_gray = cv2.cvtColor(rendered_image, cv2.COLOR_BGR2GRAY)

        # SSIMï¼ˆæ§‹é€ çš„é¡ä¼¼æ€§ï¼‰ã®è¨ˆç®—
        if SKIMAGE_SSIM_AVAILABLE:
            score, diff = ssim(original_gray, rendered_gray, full=True)
            diff = (diff * 255).astype("uint8")
        else:
            # SSIMãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ã€ç°¡æ˜“çš„ãªæ¯”è¼ƒã‚’è¡Œã†
            diff = cv2.absdiff(original_gray, rendered_gray)
            score = 1.0 - (np.sum(diff) / (255.0 * diff.size))

        # å·®åˆ†ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ä½œæˆ
        heatmap = cv2.applyColorMap(diff, cv2.COLORMAP_JET)

        # åˆ†æçµæœç”¨ã«å·®åˆ†ã®å¤§ãã„ã‚¨ãƒªã‚¢ã‚’ç‰¹å®š
        threshold = 50  # å·®åˆ†ã®é–¾å€¤
        _, thresholded = cv2.threshold(diff, threshold, 255, cv2.THRESH_BINARY)

        # å·®åˆ†ã®å¤§ãã„é ˜åŸŸã‚’æ¤œå‡º
        contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # å·®åˆ†ã‚¨ãƒªã‚¢ã®æƒ…å ±ã‚’åé›†
        difference_areas = []
        for contour in contours:
            # ååˆ†ãªå¤§ãã•ã®é ˜åŸŸã®ã¿å‡¦ç†
            if cv2.contourArea(contour) > 100:  # å°ã•ã™ãã‚‹å·®åˆ†ã¯ç„¡è¦–
                x, y, w, h = cv2.boundingRect(contour)
                difference_areas.append({
                    'x': int(x),
                    'y': int(y),
                    'width': int(w),
                    'height': int(h),
                    'area': int(cv2.contourArea(contour))
                })

        # å·®åˆ†ã‚¨ãƒªã‚¢ã‚’é¢ç©é †ã«ã‚½ãƒ¼ãƒˆ
        difference_areas.sort(key=lambda x: x['area'], reverse=True)

        # çµæœã‚’ã¾ã¨ã‚ã‚‹
        return {
            'success': True,
            'ssim_score': float(score),
            'is_similar': score >= 0.85,  # é¡ä¼¼æ€§ã®é–¾å€¤
            'differences': difference_areas[:5],  # ä¸Šä½5ã¤ã®å·®åˆ†ã‚¨ãƒªã‚¢ã‚’è¿”ã™
            'diff_heatmap': heatmap  # å·®åˆ†ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
        }

    except Exception as e:
        logger.error(f"ç”»åƒæ¯”è¼ƒã‚¨ãƒ©ãƒ¼: {str(e)}")
        traceback.print_exc()
        return {
            'success': False,
            'error': str(e),
            'ssim_score': 0,
            'differences': None
        }


def generate_feedback(comparison_result):
    """
    æ¯”è¼ƒçµæœã«åŸºã¥ã„ã¦Claudeã¸ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆã™ã‚‹

    Args:
        comparison_result: ç”»åƒæ¯”è¼ƒçµæœ

    Returns:
        string: Claudeã¸ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æ–‡
    """
    if not comparison_result['success']:
        return "æ¯”è¼ƒå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚³ãƒ¼ãƒ‰ã‚’ç¢ºèªã—ã¦å†ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"

    ssim_score = comparison_result['ssim_score']
    differences = comparison_result['differences']

    if ssim_score >= 0.95:
        return "ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°çµæœã¯å…ƒã®ãƒ‡ã‚¶ã‚¤ãƒ³ã«ã¨ã¦ã‚‚è¿‘ã„ã§ã™ã€‚ç´ æ™´ã‚‰ã—ã„å†ç¾æ€§ã§ã™ã€‚"

    if ssim_score >= 0.85:
        return "ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°çµæœã¯å…ƒã®ãƒ‡ã‚¶ã‚¤ãƒ³ã«ååˆ†è¿‘ã„ã§ã™ãŒã€ç´°ã‹ã„èª¿æ•´ã®ä½™åœ°ãŒã‚ã‚Šã¾ã™ã€‚"

    # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ãƒ™ãƒ¼ã‚¹éƒ¨åˆ†
    feedback = f"ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°çµæœã¨å…ƒã®ãƒ‡ã‚¶ã‚¤ãƒ³ã«ã¯ç›¸é•ç‚¹ãŒã‚ã‚Šã¾ã™ï¼ˆé¡ä¼¼åº¦ã‚¹ã‚³ã‚¢: {ssim_score:.2f}ï¼‰ã€‚\n"

    # å·®åˆ†ã‚¨ãƒªã‚¢ã«åŸºã¥ããƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¿½åŠ 
    if differences and len(differences) > 0:
        feedback += "ä»¥ä¸‹ã®éƒ¨åˆ†ã§ä¸»ãªç›¸é•ãŒè¦‹ã‚‰ã‚Œã¾ã™ï¼š\n"

        for i, area in enumerate(differences[:3]):  # æœ€å¤§3ã¤ã®ã‚¨ãƒªã‚¢ã«ã¤ã„ã¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
            x, y, width, height = area['x'], area['y'], area['width'], area['height']

            # ã‚¨ãƒªã‚¢ã®ä½ç½®ã«åŸºã¥ã„ã¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¨æ¸¬
            position_desc = "ä¸Šéƒ¨" if y < 300 else "ä¸­å¤®éƒ¨" if y < 600 else "ä¸‹éƒ¨"

            # ç›¸å¯¾çš„ãªä½ç½®ã‚’è¿½åŠ 
            horizontal_pos = "å·¦å´" if x < 300 else "ä¸­å¤®" if x < 600 else "å³å´"

            feedback += f"{i+1}. ãƒ‡ã‚¶ã‚¤ãƒ³ã®{position_desc}{horizontal_pos}ï¼ˆåº§æ¨™: x={x}, y={y}, å¹…={width}, é«˜ã•={height}ï¼‰ã®ã‚¨ãƒªã‚¢ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"

        # ä¸€èˆ¬çš„ãªä¿®æ­£ææ¡ˆ
        feedback += "\nè€ƒãˆã‚‰ã‚Œã‚‹å•é¡Œç‚¹ï¼š\n"
        feedback += "- è¦ç´ ã®é…ç½®ã‚„ã‚µã‚¤ã‚ºãŒå…ƒã®ãƒ‡ã‚¶ã‚¤ãƒ³ã¨ç•°ãªã£ã¦ã„ã‚‹\n"
        feedback += "- è‰²ã‚„ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆãŒæ­£ç¢ºã«å†ç¾ã•ã‚Œã¦ã„ãªã„\n"
        feedback += "- ãƒ•ã‚©ãƒ³ãƒˆã‚„ãƒ†ã‚­ã‚¹ãƒˆã‚¹ã‚¿ã‚¤ãƒ«ãŒå…ƒã®ãƒ‡ã‚¶ã‚¤ãƒ³ã¨ä¸€è‡´ã—ã¦ã„ãªã„\n"
        feedback += "- ä½™ç™½ã‚„ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãŒç•°ãªã£ã¦ã„ã‚‹\n"

        # ä¿®æ­£ã‚¢ãƒ‰ãƒã‚¤ã‚¹
        feedback += "\næ”¹å–„ã®ãŸã‚ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ï¼š\n"
        feedback += "- è¦ç´ ã®ä½ç½®ã¨ã‚µã‚¤ã‚ºã‚’å…ƒã®ãƒ‡ã‚¶ã‚¤ãƒ³ã«åˆã‚ã›ã¦èª¿æ•´ã™ã‚‹\n"
        feedback += "- è‰²ã‚„ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ­£ç¢ºã«å†ç¾ã™ã‚‹\n"
        feedback += "- é©åˆ‡ãªãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºã¨ã‚¦ã‚§ã‚¤ãƒˆã‚’è¨­å®šã™ã‚‹\n"
        feedback += "- ä½™ç™½ã‚„ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚’å…ƒã®ãƒ‡ã‚¶ã‚¤ãƒ³ã«åˆã‚ã›ã‚‹\n"

    return feedback

def analyze_layout_structure(text_blocks, image_sections=None):
    """
    ãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒãƒ–ãƒ­ãƒƒã‚¯ã®ä½ç½®ã‚’å…ƒã«ã€ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ§‹é€ ã‚’æ¨å®šã™ã‚‹

    Args:
        text_blocks: ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã®ãƒªã‚¹ãƒˆ
        image_sections: ç”»åƒãƒ–ãƒ­ãƒƒã‚¯ã®ãƒªã‚¹ãƒˆ (çœç•¥å¯èƒ½)

    Returns:
        dict: ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ§‹é€ æƒ…å ±
    """
    logger.info("========== ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ§‹é€ è§£æé–‹å§‹ ==========")
    logger.info(f"ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯æ•°: {len(text_blocks) if text_blocks else 0}")
    logger.info(f"ç”»åƒã‚»ã‚¯ã‚·ãƒ§ãƒ³æ•°: {len(image_sections) if image_sections else 0}")

    layout_type = "single-column"
    image_pos = None
    text_pos = "center"

    # ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯æ—©æœŸãƒªã‚¿ãƒ¼ãƒ³
    if not text_blocks or len(text_blocks) == 0:
        logger.info("ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ãŒã‚ã‚Šã¾ã›ã‚“ - ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè§£æã‚’ä¸­æ­¢ã—ã¾ã™")
        result = {
            "layoutType": "unknown",
            "hasImage": bool(image_sections),
            "imagePosition": None,
            "textPosition": None,
            "sectionCount": 0
        }
        logger.info(f"ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ§‹é€ è§£æçµæœ: {result}")
        logger.info("========== ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ§‹é€ è§£æçµ‚äº† ==========")
        return result

    # ã‚«ãƒ©ãƒ æ¨å®šï¼ˆXåº§æ¨™ã«åã‚ŠãŒã‚ã‚‹ã‹ã©ã†ã‹ï¼‰
    x_positions = [block['position']['x'] for block in text_blocks if 'position' in block]
    if not x_positions:
        logger.info("æœ‰åŠ¹ãªä½ç½®æƒ…å ±ã‚’æŒã¤ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ãŒã‚ã‚Šã¾ã›ã‚“")
        result = {
            "layoutType": "unknown",
            "hasImage": bool(image_sections),
            "imagePosition": None,
            "textPosition": None,
            "sectionCount": 0
        }
        logger.info(f"ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ§‹é€ è§£æçµæœ: {result}")
        logger.info("========== ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ§‹é€ è§£æçµ‚äº† ==========")
        return result

    avg_x = sum(x_positions) / len(x_positions)
    left_count = len([x for x in x_positions if x < avg_x])
    right_count = len([x for x in x_positions if x >= avg_x])

    logger.info(f"Xåº§æ¨™åˆ†æ: å¹³å‡={avg_x:.1f}, å·¦å´={left_count}å€‹, å³å´={right_count}å€‹")

    # ç”»é¢ä¸­å¤®ã‹ã‚‰ã®æ°´å¹³ãƒãƒ©ãƒ³ã‚¹ã§åˆ¤å®š
    # (ã“ã®ãƒ­ã‚¸ãƒƒã‚¯ã¯ç”»é¢ã‚µã‚¤ã‚ºã«å¿œã˜ã¦èª¿æ•´ã™ã‚‹å¿…è¦ãŒã‚ã‚‹)
    if abs(left_count - right_count) > 1:
        layout_type = "two-column"
        text_pos = "right" if left_count < right_count else "left"
        logger.info(f"ãƒ†ã‚­ã‚¹ãƒˆåã‚Šæ¤œå‡º: {text_pos}å´ã«åã£ã¦ã„ã¾ã™ â†’ 2ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ")
    else:
        logger.info("ãƒ†ã‚­ã‚¹ãƒˆåˆ†å¸ƒã¯å‡ç­‰ â†’ 1ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ")

    # ã‚°ãƒªãƒƒãƒ‰ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®æ¤œå‡º
    # ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã®Yåº§æ¨™ã‚’åˆ†æã—ã¦è¦å‰‡çš„ãªã‚°ãƒªãƒƒãƒ‰ã‹ã©ã†ã‹ã‚’åˆ¤å®š
    y_positions = [block['position']['y'] for block in text_blocks if 'position' in block]
    y_positions.sort()
    logger.info(f"Yåº§æ¨™ã‚½ãƒ¼ãƒˆçµæœ: {y_positions}")

    # éš£æ¥ã™ã‚‹è¦ç´ é–“ã®Yåº§æ¨™ã®å·®ã‚’è¨ˆç®—
    y_diffs = [y_positions[i+1] - y_positions[i] for i in range(len(y_positions)-1)]

    if y_diffs:
        logger.info(f"Yåº§æ¨™ã®å·®åˆ†: {y_diffs}")
        avg_diff = sum(y_diffs) / len(y_diffs)
        logger.info(f"Yåº§æ¨™ã®å¹³å‡å·®åˆ†: {avg_diff:.1f}px")

        # å·®ãŒä¸€å®šã®å€¤ã«è¿‘ã„ã‹ã©ã†ã‹ã‚’ç¢ºèª (ã‚°ãƒªãƒƒãƒ‰ã®ç‰¹å¾´)
        if len(y_diffs) > 2:
            avg_diff = sum(y_diffs) / len(y_diffs)
            regular_spacing = all(abs(diff - avg_diff) < avg_diff * 0.3 for diff in y_diffs)

            if regular_spacing:
                logger.info("Yæ–¹å‘ã«ç­‰é–“éš”é…ç½®ã‚’æ¤œå‡º")
            else:
                logger.info("Yæ–¹å‘ã®é–“éš”ã¯ä¸è¦å‰‡")

            # æ¨ªæ–¹å‘ã®ä½ç½®ã‚‚è€ƒæ…®ã—ã¦ã€ã‚«ãƒ¼ãƒ‰ã‚°ãƒªãƒƒãƒ‰ã‹ã©ã†ã‹ã‚’åˆ¤å®š
            x_clusters = {}
            for block in text_blocks:
                if 'position' in block:
                    pos = block['position']
                    x_cluster = pos['x'] // 100  # 100pxå˜ä½ã§ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
                    if x_cluster not in x_clusters:
                        x_clusters[x_cluster] = 0
                    x_clusters[x_cluster] += 1

            logger.info(f"Xæ–¹å‘ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼: {x_clusters}")

            # è¤‡æ•°ã®æ¨ªæ–¹å‘ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãŒã‚ã‚Šã€ç¸¦æ–¹å‘ãŒç­‰é–“éš”ãªã‚‰ã‚°ãƒªãƒƒãƒ‰
            if len(x_clusters) > 1 and regular_spacing:
                layout_type = "card-grid"
                logger.info("ç¸¦æ–¹å‘ã®ç­‰é–“éš”ã¨è¤‡æ•°ã®æ¨ªæ–¹å‘ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’æ¤œå‡º â†’ ã‚«ãƒ¼ãƒ‰ã‚°ãƒªãƒƒãƒ‰ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ")

    # ç”»åƒä½ç½®ã®åˆ¤å®šï¼ˆã‚ã‚Œã°ï¼‰
    if image_sections:
        logger.info(f"ç”»åƒã‚»ã‚¯ã‚·ãƒ§ãƒ³è§£æ: {len(image_sections)}å€‹")
        try:
            # ä¸€ç•ªå¤§ããªç”»åƒã®ä½ç½®ã‚’å‚è€ƒã«ã™ã‚‹ï¼ˆè¤‡æ•°ã‚ã‚‹å ´åˆï¼‰
            if isinstance(image_sections, list) and len(image_sections) > 0:
                # position ã‚­ãƒ¼ãŒã‚ã‚‹è¦ç´ ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                valid_sections = [s for s in image_sections if 'position' in s]
                logger.info(f"æœ‰åŠ¹ãªä½ç½®æƒ…å ±ã‚’æŒã¤ç”»åƒã‚»ã‚¯ã‚·ãƒ§ãƒ³: {len(valid_sections)}å€‹")

                if valid_sections:
                    largest = max(valid_sections,
                                 key=lambda s: s['position'].get('width', 0) * s['position'].get('height', 0))
                    img_x = largest['position'].get('left', 0) or largest['position'].get('x', 0)
                    img_y = largest['position'].get('top', 0) or largest['position'].get('y', 0)
                    img_width = largest['position'].get('width', 0)
                    img_height = largest['position'].get('height', 0)

                    logger.info(f"æœ€å¤§ç”»åƒã‚»ã‚¯ã‚·ãƒ§ãƒ³: ä½ç½®(x={img_x}, y={img_y}), ã‚µã‚¤ã‚º({img_width}x{img_height})")

                    # ç”»åƒã®ä½ç½®ã‚’æ°´å¹³æ–¹å‘ã§åˆ¤å®š
                    if img_x < avg_x - 100:  # å·¦ã«åã£ã¦ã„ã‚‹
                        image_pos = "left"
                        logger.info("ç”»åƒã¯å·¦å´ã«é…ç½®ã•ã‚Œã¦ã„ã¾ã™")
                    elif img_x > avg_x + 100:  # å³ã«åã£ã¦ã„ã‚‹
                        image_pos = "right"
                        logger.info("ç”»åƒã¯å³å´ã«é…ç½®ã•ã‚Œã¦ã„ã¾ã™")
                    else:
                        image_pos = "center"
                        logger.info("ç”»åƒã¯ä¸­å¤®ã«é…ç½®ã•ã‚Œã¦ã„ã¾ã™")

                    # ãƒ†ã‚­ã‚¹ãƒˆã®å‚ç›´ä½ç½®ã‚‚åˆ¤å®š
                    avg_text_y = sum(y_positions) / len(y_positions)
                    logger.info(f"ãƒ†ã‚­ã‚¹ãƒˆYåº§æ¨™å¹³å‡: {avg_text_y:.1f}, ç”»åƒYåº§æ¨™: {img_y}")

                    if img_y < min(y_positions):
                        # ç”»åƒãŒã™ã¹ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆã‚ˆã‚Šä¸Šã«ã‚ã‚‹
                        image_pos = "top"
                        logger.info("ç”»åƒã¯ã™ã¹ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆã‚ˆã‚Šä¸Šã«ã‚ã‚Šã¾ã™")
                    elif img_y > max(y_positions):
                        # ç”»åƒãŒã™ã¹ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆã‚ˆã‚Šä¸‹ã«ã‚ã‚‹
                        image_pos = "bottom"
                        logger.info("ç”»åƒã¯ã™ã¹ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆã‚ˆã‚Šä¸‹ã«ã‚ã‚Šã¾ã™")
        except Exception as e:
            logger.error(f"ç”»åƒä½ç½®åˆ¤å®šã‚¨ãƒ©ãƒ¼: {e}")
            image_pos = None

    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ•°ã®æ¨å®š
    # Yåº§æ¨™ã®åˆ†å¸ƒã‹ã‚‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ•°ã‚’åˆ¤å®š
    section_count = 1
    if y_positions:
        # Yåº§æ¨™ã‚’ã‚½ãƒ¼ãƒˆã—ã€å¤§ããªã‚®ãƒ£ãƒƒãƒ—ã‚’æ¢ã™
        y_positions.sort()
        jumps = []
        for i in range(1, len(y_positions)):
            if y_positions[i] - y_positions[i-1] > 100:  # 100pxä»¥ä¸Šã®ã‚®ãƒ£ãƒƒãƒ—ã§ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†ã‘
                jumps.append(i)
                logger.info(f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†å‰²ç‚¹ã‚’æ¤œå‡º: Y={y_positions[i-1]}-{y_positions[i]} (ã‚®ãƒ£ãƒƒãƒ—={y_positions[i]-y_positions[i-1]}px)")

        # ã‚¸ãƒ£ãƒ³ãƒ—ã®æ•°+1ãŒã‚»ã‚¯ã‚·ãƒ§ãƒ³æ•°
        section_count = len(jumps) + 1
        logger.info(f"æ¤œå‡ºã•ã‚ŒãŸã‚»ã‚¯ã‚·ãƒ§ãƒ³æ•°: {section_count}")

    result = {
        "layoutType": layout_type,
        "hasImage": bool(image_sections),
        "imagePosition": image_pos,
        "textPosition": text_pos,
        "sectionCount": section_count
    }

    logger.info(f"ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ§‹é€ è§£æçµæœ: {result}")
    logger.info("========== ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ§‹é€ è§£æçµ‚äº† ==========")
    return result

def format_analysis_for_ai(analysis_data, format_type="markdown"):
    """
    AIå‘ã‘ã«è§£æãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã—ã¾ã™ã€‚

    Args:
        analysis_data: ç”»åƒè§£æãƒ‡ãƒ¼ã‚¿
        format_type: å‡ºåŠ›å½¢å¼ (markdown, json, text)

    Returns:
        string: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸè§£æãƒ‡ãƒ¼ã‚¿
    """
    logger.info(f"ğŸ“Š AIå‘ã‘ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå‡¦ç†é–‹å§‹ï¼ˆformat_analysis_for_aiï¼‰- å½¢å¼: {format_type}")

    if not analysis_data:
        logger.warning("âš ï¸ è§£æãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
        return ""

    # è§£æãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬æƒ…å ±ã‚’ãƒ­ã‚°ã«å‡ºåŠ›
    input_data_size = len(str(analysis_data))
    has_text = 'text' in analysis_data and len(analysis_data['text'].get('blocks', [])) > 0
    has_colors = 'colors' in analysis_data and len(analysis_data['colors'].get('colors', [])) > 0
    has_elements = 'elements' in analysis_data and len(analysis_data['elements'].get('elements', [])) > 0
    has_layout = 'layout' in analysis_data and bool(analysis_data['layout'])

    logger.info(f"ğŸ“¥ å…¥åŠ›ãƒ‡ãƒ¼ã‚¿æƒ…å ±: ã‚µã‚¤ã‚º={input_data_size}æ–‡å­—, ãƒ†ã‚­ã‚¹ãƒˆ={has_text}, è‰²æƒ…å ±={has_colors}, è¦ç´ ={has_elements}, ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ={has_layout}")

    output = ""
    # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚¿ã‚¤ãƒ—ã«åŸºã¥ã„ã¦å‡ºåŠ›ã‚’ç”Ÿæˆ
    if format_type == "markdown" or format_type == "text":
        # ä¸€æ™‚çš„ã«å…¨ã¦JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¨ã—ã¦å‡ºåŠ›
        import json
        output = json.dumps(analysis_data, ensure_ascii=False, indent=2)
        logger.info(f"âš ï¸ {format_type}å½¢å¼ã¯æœªå®Ÿè£…ã®ãŸã‚ã€JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å‡ºåŠ›ã—ã¾ã™")
    else:  # json
        import json
        output = json.dumps(analysis_data, ensure_ascii=False, indent=2)

    output_size = len(output)
    logger.info(f"ğŸ“¤ AIå‘ã‘ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå®Œäº†: å‡ºåŠ›ã‚µã‚¤ã‚º={output_size}æ–‡å­— ({output_size/1024:.1f}KB)")
    logger.info(f"âœ… AIå‘ã‘ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå‡¦ç†å®Œäº†")

    return output
